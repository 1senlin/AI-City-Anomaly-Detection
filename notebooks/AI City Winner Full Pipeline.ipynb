{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/data/modules\")\n",
    "\n",
    "# local files from their github\n",
    "import AICity2019_winner.utils.utils as utils\n",
    "import AICity2019_winner.src.reid.modeling as modeling\n",
    "import AICity2019_winner.src.reid.misc as misc\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.preprocessing as prep\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import linear_model\n",
    "import skimage\n",
    "from skimage.measure import label\n",
    "import scipy\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "import itertools\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoReader:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        \n",
    "        \n",
    "        self.nframes = None\n",
    "        self.framerate = None\n",
    "        self.img_shape = None\n",
    "        self._set_video_info()\n",
    "        \n",
    "    def load_video(self, interval=1):\n",
    "        \"\"\"\n",
    "        Loads the images of the video\n",
    "        Returns a generator with the images, and the corresponding frame numbers.\n",
    "        \n",
    "        interval: Interval between frames returned. eg. 1 = every frame, 20 = every 20th frame.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Loads a video with opencv, returns PIL a generator\n",
    "        def read_frames():\n",
    "            vid = cv.VideoCapture(self.filename)\n",
    "\n",
    "            for i in frame_nums:\n",
    "                vid.set(cv.CAP_PROP_POS_FRAMES, i)\n",
    "\n",
    "                has_frame, img = vid.read()\n",
    "\n",
    "                if has_frame:\n",
    "                    yield img\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            vid.release()\n",
    "            \n",
    "        frame_nums = range(0, self.nframes, interval)\n",
    "        \n",
    "        return read_frames(), frame_nums\n",
    "\n",
    "    def get_frame(self, n):\n",
    "        \"\"\"\n",
    "        Returns the image at a specific frame number\n",
    "        \"\"\"\n",
    "        \n",
    "        vid = cv.VideoCapture(self.filename)\n",
    "        vid.set(cv.CAP_PROP_POS_FRAMES, n)\n",
    "\n",
    "        _, img = vid.read()\n",
    "\n",
    "\n",
    "        vid.release()\n",
    "        return img\n",
    "    \n",
    "    def _set_video_info(self):\n",
    "        vid = cv.VideoCapture(self.filename)\n",
    "        _, img = vid.read()\n",
    "\n",
    "        self.nframes = int(vid.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "        self.framerate = vid.get(cv.CAP_PROP_FPS)\n",
    "        self.img_shape = img.shape\n",
    "\n",
    "        vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageReader:\n",
    "    def __init__(self, folder):\n",
    "        self.folder = folder\n",
    "        \n",
    "        self.filenames = sorted(os.listdir(folder), key=lambda f: int(f[:-4])) # \"123.jpg\" -> sort by 123 instead of the full string\n",
    "        \n",
    "    def load_images(self):\n",
    "        \"\"\"\n",
    "        Loads the images, returning them as a generator.\n",
    "        \n",
    "        \"\"\"\n",
    "        for filename in self.filenames:\n",
    "            file_path = os.path.join(self.folder, filename)\n",
    "            img = cv.imread(file_path)\n",
    "            \n",
    "            yield img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Background Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_background(images, interval=20, alpha=0.1, start_frame=1, threshold=5):\n",
    "    \"\"\"\n",
    "    Calculates the background over all of the images by averaging them.\n",
    "    \n",
    "    images: iterable of numpy images\n",
    "    interval: number of images between each background calculation\n",
    "    alpha: weighting of averaging. high = more of new frame, low = more of running average.\n",
    "    start_frame: frame number to start averaging on\n",
    "    threshold: Mean Absolute Error threshold between frames. Only calculates if there is a significant difference.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    running_bg = None\n",
    "    prev_img = None\n",
    "    for i, img in enumerate(images):\n",
    "        if running_bg is None: # initial image\n",
    "            running_bg = img\n",
    "            prev_img = img\n",
    "            continue\n",
    "        \n",
    "        if (i - start_frame) % interval != 0: # every (i * internal_frame + start_frame) frames, do the calcs\n",
    "            continue\n",
    "        \n",
    "        diff = np.mean(np.abs(prev_img - img))\n",
    "        if diff > threshold: # if new image is significantly different from old\n",
    "            running_bg = (1 - alpha) * running_bg + alpha * img # new background\n",
    "            yield running_bg, i\n",
    "        \n",
    "        else:\n",
    "            yield running_bg * 0, i  # black image\n",
    "            \n",
    "        prev_img = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bg_tensor(images, interval=20, alpha=0.1, start_frame=1, threshold=5):\n",
    "    \"\"\"\n",
    "    Same as calc_background function, uses GPU instead. Doesn't seem to speed it up much.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    running_bg = None\n",
    "    prev_img = None\n",
    "    for i, img in enumerate(images):\n",
    "        img = torch.as_tensor(img, device=\"cuda\", dtype=torch.float16)\n",
    "        \n",
    "        if running_bg is None: # initial image\n",
    "            running_bg = img.clone()\n",
    "            prev_img = img.clone()\n",
    "            continue\n",
    "        \n",
    "        if (i - start_frame) % interval != 0: # every (i * internal_frame + start_frame) frames, do the calcs\n",
    "            continue\n",
    "        \n",
    "        diff = prev_img.sub_(img).abs_().mean()\n",
    "        if diff.item() > threshold: # if new image is significantly different from old\n",
    "            running_bg.mul_(1 - alpha).add_(img.mul(alpha)) # new background\n",
    "            yield running_bg.to(dtype=torch.uint8, device=\"cpu\", non_blocking=True).numpy(), i\n",
    "        \n",
    "        else:\n",
    "            yield running_bg.mul(0).to(dtype=torch.uint8, device=\"cpu\", non_blocking=True).numpy(), i  # black image\n",
    "            \n",
    "        prev_img = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bg_full_video(video_path, output_folder, interval=20, alpha=0.1, start_frame=1, threshold=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Create background images for a single video. Assumes output_folder exists already.\n",
    "    \n",
    "    video_path: path to raw video\n",
    "    output_folder: folder to put background images in\n",
    "    interval, alpha, start_frame, threshold: see calc_background function\n",
    "    verbose: print out progress\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    vid = VideoReader(video_path)\n",
    "    raw_imgs, _ = vid.load_video()\n",
    "    bg_images = calc_background(raw_imgs, interval, alpha, start_frame, threshold)\n",
    "    \n",
    "    for bg_img, frame in bg_images:\n",
    "        filename = os.path.join(output_folder, f\"{frame}.jpg\")\n",
    "        cv.imwrite(filename, bg_img)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{frame}/{vid.nframes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector:\n",
    "    \"\"\"\n",
    "    built using: https://github.com/open-mmlab/mmdetection/tree/master/configs/htc\n",
    "    (HTC + DCN + ResNeXt-101-FPN, mAP=50.7 model)\n",
    "    \n",
    "    Might take some fiddling to make it work with any mmdetection model\n",
    "    \n",
    "    config_file: \"htc/htc_dconv_c3-c5_mstrain_400_1400_x101_64x4d_fpn_20e.py\"\n",
    "    checkpoint_file: \"htc_dconv_c3-c5_mstrain_400_1400_x101_64x4d_fpn_20e_20190408-0e50669c.pth\"\n",
    "    class_restrictions: list of classes to detect, others are discarded. if None, it will detect all classes\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_path, model_path, verbose_interval=None, class_restrictions=set([2,3,5,7])):\n",
    "        torch.cuda.empty_cache()\n",
    "        self.model = init_detector(config_path, model_path, device='cuda:0')\n",
    "        self.class_labels = self.model.CLASSES\n",
    "        self.class_restrictions = class_restrictions\n",
    "        \n",
    "        self.verbose_interval = verbose_interval\n",
    "        \n",
    "    def detect_objects(self, img):\n",
    "        \"\"\"\n",
    "        Runs object detection on an image.\n",
    "        Returns bounding boxes [x1, y1, x2, y2], class labels, and confidence scores\n",
    "        \"\"\"\n",
    "        \n",
    "        results = inference_detector(self.model, img) # I think they are segmentations, not sure though\n",
    "        if len(results) == 2:\n",
    "            results, segments = results\n",
    "        \n",
    "        bbox_and_scores = np.vstack(results)\n",
    "        bboxes, scores = bbox_and_scores[:, :4], bbox_and_scores[:, 4]\n",
    "        labels = np.concatenate([[i] * len(bbox) for i, bbox in enumerate(results)]).astype(int)\n",
    "        \n",
    "        order = np.argsort(scores)[::-1] # sort\n",
    "        return bboxes[order], labels[order], scores[order]\n",
    "    \n",
    "    def detect_crop(self, img, crop_boxes):\n",
    "        \"\"\"\n",
    "        Splits an image into boxes, upscales them, performs detection, downscales detections, merges detections\n",
    "        \n",
    "        img: numpy array of image\n",
    "        crop_boxes: list of crop bounding boxes [x1, y1, x2, y2]\n",
    "        \n",
    "        returns: detection results [[x1, y1, x2, y2, score, class], ...]\n",
    "        \"\"\"\n",
    "        pil_img = PIL.Image.fromarray(img)\n",
    "        crops = crop_image(pil_img, crop_boxes)\n",
    "        resized, biggest = resize_crops(crops)\n",
    "        \n",
    "        resized_np = (np.array(img) for img in resized)\n",
    "        \n",
    "        crop_results = self.detect_images(resized_np, verbose=False)\n",
    "        \n",
    "        bboxes = []\n",
    "        for i, x1, y1, x2, y2, score, cls in crop_results.values:\n",
    "            bboxes.append(cropped_detection_to_original((x1, y1, x2, y2), crop_boxes[int(i)], biggest))\n",
    "        bboxes = np.array(bboxes)\n",
    "        \n",
    "        scores = crop_results[\"score\"].values\n",
    "        labels = crop_results[\"class\"].values\n",
    "        \n",
    "        order = np.argsort(scores)[::-1] # sort\n",
    "        return bboxes[order], labels[order], scores[order]\n",
    "\n",
    "    \n",
    "    \n",
    "    def detect_images(self, images, frames=None, crop_boxes=None, verbose=True):\n",
    "        \"\"\"\n",
    "        Runs object detection on images, yields all results at the end.\n",
    "        \n",
    "        images: iterable of numpy array images\n",
    "        frames: iterable of frame numbers/names corresponding to images\n",
    "        crop_boxes: if provided, will crop and rescale for detection\n",
    "        verbose: override for self.verbose_interval\n",
    "        \n",
    "        Returns dataframe with detection results\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        results = []\n",
    "        for i, img in enumerate(images):\n",
    "            frame = i if frames is None else frames[i]\n",
    "\n",
    "            if crop_boxes is not None:\n",
    "                bboxes, labels, scores = self.detect_crop(img, crop_boxes)\n",
    "            else:\n",
    "                bboxes, labels, scores = self.detect_objects(img)\n",
    "            \n",
    "            for (x1, y1, x2, y2), cls, score in zip(bboxes, labels, scores):\n",
    "                if self.class_restrictions and cls not in self.class_restrictions:\n",
    "                    continue \n",
    "                \n",
    "                results.append([frame, x1, y1, x2, y2, score, cls])\n",
    "                \n",
    "            if verbose and self.verbose_interval and (i % self.verbose_interval) == 0:\n",
    "                print(f\"Detecting image: {frame}\")\n",
    "#                 print(*results[-5:], sep=\"\\n\")\n",
    "                \n",
    "        return pd.DataFrame(data=results, columns=[\"frame\", \"x1\", \"y1\", \"x2\", \"y2\", \"score\", \"class\"])\n",
    "    \n",
    "    \n",
    "    def detect_images_generator(self, images, frames=None, crop_boxes=None, verbose=True):\n",
    "        \"\"\"\n",
    "        Runs object detection on images, yielding the results one frame at a time.\n",
    "        \n",
    "        images: iterable of numpy array images\n",
    "        frames: iterable of frame numbers/names corresponding to images\n",
    "        crop_boxes: if provided, will crop and rescale for detection\n",
    "        verbose: override for self.verbose_interval\n",
    "        \n",
    "        Returns frame, dataframe with detection results.\n",
    "        \"\"\"\n",
    "        \n",
    "        for i, img in enumerate(images):\n",
    "            frame = i if frames is None else frames[i]\n",
    "\n",
    "            if crop_boxes is not None:\n",
    "                bboxes, labels, scores = self.detect_crop(img, crop_boxes)\n",
    "            else:\n",
    "                bboxes, labels, scores = self.detect_objects(img)\n",
    "                \n",
    "            results = []\n",
    "            for (x1, y1, x2, y2), cls, score in zip(bboxes, labels, scores):\n",
    "                if self.class_restrictions and cls not in self.class_restrictions:\n",
    "                    continue \n",
    "                \n",
    "                results.append([frame, x1, y1, x2, y2, score, cls])\n",
    "                \n",
    "            yield frame, pd.DataFrame(data=results, columns=[\"frame\", \"x1\", \"y1\", \"x2\", \"y2\", \"score\", \"class\"])\n",
    "        \n",
    "        \n",
    "            \n",
    "    \n",
    "    def label_image(self, img, bboxes, labels, scores, score_thresh=0.1):\n",
    "        \"\"\"\n",
    "        Returns an image with bounding boxes drawn on it\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        def get_class_color(cls):\n",
    "            return (0, 0, 255) # todo\n",
    "        \n",
    "        img = np.copy(img)\n",
    "        \n",
    "        for (x1, y1, x2, y2), cls, score in zip(bboxes, labels, scores):\n",
    "            if score < score_thresh:\n",
    "                continue\n",
    "            \n",
    "            col = get_class_color(cls)\n",
    "            cv.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), col, 1) # draw boxes\n",
    "            \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video(video_path, output_path, model_config_path, model_checkpoint_path):\n",
    "    \"\"\"\n",
    "    Runs object detection on a video. Saves results as a csv.\n",
    "    \"\"\"\n",
    "    \n",
    "    vid = VideoReader(video_path)\n",
    "    images, filenames = vid.load_video()\n",
    "    \n",
    "    model = Detector(model_config_path, model_checkpoint_path)\n",
    "    results = model.detect_images(images, filenames)\n",
    "    \n",
    "    results.to_csv(output_path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image_folder(image_folder, output_path, model_config_path, model_checkpoint_path):\n",
    "    \"\"\"\n",
    "    Runs object detection on a folder of images. Saves the results to a csv\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    img_reader = ImageReader(image_folder)\n",
    "    \n",
    "    model = Detector(model_config_path, model_checkpoint_path)\n",
    "    results = model.detect_images(img_reader.load_images(), img_reader.filenames)\n",
    "    \n",
    "    results.to_csv(output_path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Perspective Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_regression(df, plot=False):\n",
    "    \"\"\"\n",
    "    Does linear regression of y-position vs vehicle height\n",
    "    h = a * y + b\n",
    "    \n",
    "    df: DataFrame with columns: [x1, y1, x2, y2], the positions of the bounding boxes\n",
    "    plot: plot the regression results\n",
    "    \"\"\"\n",
    "    \n",
    "    y = (df[\"y1\"] + df[\"y2\"]) / 2 # center y coord of bbox\n",
    "    h = np.sqrt((df[\"y2\"] - df[\"y1\"]) * (df[\"x2\"] - df[\"x1\"]))  # sqrt bbox area\n",
    "\n",
    "    y = y[np.isfinite(h)] # Remove some wonky values\n",
    "    h = h[np.isfinite(h)]\n",
    "\n",
    "        \n",
    "    \n",
    "    regression = linear_model.LinearRegression()\n",
    "    \n",
    "    regression.fit(\n",
    "        np.array(y).reshape(-1, 1), # (n, 1)\n",
    "        np.array(h) # (n)\n",
    "    )\n",
    "    \n",
    "    a, b = regression.coef_[0], regression.intercept_\n",
    "    \n",
    "    if plot:\n",
    "        f = lambda x: a * x + b\n",
    "        # plot points\n",
    "        plt.plot(y, h, \"o\", )\n",
    "        plt.plot([0, max(y)], [f(0), f(max(y))])\n",
    "        plt.xlabel(\"y position\")\n",
    "        plt.ylabel(\"sqrt bounding box area\")\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"a: {a}, b: {b}\")\n",
    "    \n",
    "    \n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_box_row(y_min, box_height, box_width, img_width, exclude_last=False, clip_last=True):\n",
    "    \"\"\"\n",
    "    Creates bounding boxes for a single row\n",
    "    \n",
    "    y_min: base y-coordinate for boxes\n",
    "    box_height:\n",
    "    box_width:\n",
    "    img_width:\n",
    "    exclude_last: whether or not to create the last box of the row, which usualy overlaps outside the image boundary.\n",
    "    clip_last: if true, chops the end off the last box of the row. if exclude_last == false, this has no effect.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    num_boxes = int(np.ceil(img_width / box_width))\n",
    "    x_positions = np.linspace(0, box_width * num_boxes, num_boxes + 1)\n",
    "    \n",
    "    if exclude_last: # exclude box that would be partially outside image\n",
    "        x_positions = x_positions[:-1]\n",
    "    \n",
    "    boxes = []\n",
    "    for x_min, x_max in zip(x_positions[:-1], x_positions[1:]):\n",
    "        if clip_last and x_max >= img_width: # clip last box to image boundary\n",
    "            x_max = img_width - 1\n",
    "        \n",
    "        boxes.append([int(x_min), y_min, int(x_max), y_min + box_height])\n",
    "    \n",
    "    return boxes\n",
    "\n",
    "\n",
    "def generate_crop_boxes(min_height, a_reg, b_reg, img_shape, row_capacity=3, box_aspect_ratio=2, exclude_last=False, clip_last=True):\n",
    "    \"\"\"\n",
    "    Creates all crop boxes for the image.\n",
    "    \n",
    "    min_height: minimum vehicle height\n",
    "    a_reg: linear regression coefficient for y-pos vs height\n",
    "    b_reg: linear regression intercept for y-pos vs height\n",
    "    img_shape: (height, width) of image\n",
    "    row_capacity: Vehicle capacity for each row. Not 100% sure how to explain this.\n",
    "    box_aspect_rato: width/height bounding box ratio\n",
    "    exclude_last, clip_last: see generate_box_row function.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def exp_func(x):\n",
    "        # Modified function, seems to work better/properly\n",
    "        # capacity space -> height space\n",
    "#         return int(np.exp(x) / a_reg) # theirs\n",
    "        return int(np.exp(a_reg * x)) # mine\n",
    "    \n",
    "    def log_func(x):\n",
    "        # height space -> capacity space\n",
    "        return np.log(x) / a_reg\n",
    "    \n",
    "    def f(y):\n",
    "        # h = a * y + b\n",
    "        # y position -> vehicle height at that position\n",
    "        return a_reg * y + b_reg\n",
    "    \n",
    "    def f_inv(h):\n",
    "        # vehicle height -> y position\n",
    "        return int((h - b_reg) / a_reg)\n",
    "    \n",
    "    # k * ln(k*y2+b) - k * ln(k*y1+b) this corresponds to the big integral in the paper\n",
    "    total_capacity = log_func(f(img_shape[0])) - log_func(min_height)\n",
    "    \n",
    "    num_rows = int(np.ceil(total_capacity / row_capacity))\n",
    "    stride_cap = total_capacity / num_rows # capacity stride\n",
    "    \n",
    "    start_capacity = log_func(min_height)\n",
    "    vert_capacities = np.linspace(start_capacity, start_capacity + stride_cap * num_rows, num_rows + 1)\n",
    "    \n",
    "    # convert to y coord\n",
    "#     y_positions = list(map((lambda x: exp_func(a_reg * x - b_reg)), vert_capacities)) # theirs\n",
    "    y_heights = list(map(exp_func, vert_capacities)) # mine\n",
    "    y_positions = list(map(f_inv, y_heights))\n",
    "    \n",
    "    \n",
    "    boxes = []\n",
    "    for y_min, y_max in zip(y_positions[:-1], y_positions[1:]):\n",
    "        box_width = (y_max - y_min) * box_aspect_ratio\n",
    "        \n",
    "        boxes += generate_box_row(y_min, y_max - y_min, box_width, img_shape[1], exclude_last, clip_last)\n",
    "    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, crop_boxes):\n",
    "    \"\"\"\n",
    "    img: PIL Image\n",
    "    crop_boxes: list of boxes [x1, y1, x2, y2]\n",
    "    \"\"\"\n",
    "    \n",
    "    return [img.crop(box) for box in crop_boxes]\n",
    "\n",
    "def resize_crops(crops, threshold=0.01):\n",
    "    \"\"\"\n",
    "    Resizes images to the biggest in the list.\n",
    "    Maintains aspect ratio, pads if necessary.\n",
    "    \n",
    "    Uses area to determine biggest image, might not work well if the biggest image is chopped off a bit\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    biggest_size = max((img.size for img in crops), key=np.prod)\n",
    "    biggest_aspect = biggest_size[0] / biggest_size[1]\n",
    "    \n",
    "    resized = []\n",
    "    for img in crops:\n",
    "        aspect = img.size[0] / img.size[1]\n",
    "        \n",
    "        # chopped off image -> scale and pad\n",
    "        if abs(biggest_aspect - aspect) > threshold: \n",
    "            scaled = img.resize((int(biggest_size[0] * aspect / biggest_aspect), biggest_size[1]))\n",
    "            \n",
    "            new = PIL.Image.new(\"RGB\", biggest_size, (0,0,0))\n",
    "            new.paste(scaled, scaled.getbbox())\n",
    "        \n",
    "        # normal image -> scale\n",
    "        else:\n",
    "            new = img.resize(biggest_size)\n",
    "            \n",
    "        resized.append(new)\n",
    "            \n",
    "    return resized, biggest_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crop_boxes(results_path, crop_boxes_path, img_shape, min_object_size=10, row_capacity=3, crop_box_aspect_ratio=2):\n",
    "    # Read bboxes\n",
    "    bbox_df = pd.read_csv(results_path)\n",
    "    a, b = do_regression(df=bbox_df, plot=False)\n",
    "\n",
    "    # Create crop boxes\n",
    "    crop_boxes = generate_crop_boxes(min_object_size, a, b, img_shape, row_capacity, crop_box_aspect_ratio)\n",
    "    \n",
    "    # Save crop boxes\n",
    "    pd.DataFrame(crop_boxes, columns=[\"x1\", \"y1\", \"x2\", \"y2\"]).to_csv(crop_boxes_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropped_detection_to_original(bbox, crop_box, resized_shape):\n",
    "    \"\"\"\n",
    "    Takes bounding boxes from detection on cropped, resized images.\n",
    "    Translates them to their position on the original image\n",
    "    Assumes crop boxes were not chopped off at the edge of the picture. todo\n",
    "    \n",
    "    \n",
    "    bbox: detected bounding box on image after cropping/resizing\n",
    "    crop_box: bounding box generated by generate_crop_boxes function\n",
    "    resized_shape: (height, width) of image after resizing.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Turn into numpy arrays for easier computation\n",
    "    bbox = np.reshape(bbox, (2,2))\n",
    "    crop_box = np.reshape(crop_box, (2,2))\n",
    "    resized_shape = np.array(resized_shape)\n",
    "    \n",
    "    # Calculate scales\n",
    "    crop_shape = crop_box[1] - crop_box[0]\n",
    "    resize_scale = resized_shape / crop_shape\n",
    "    \n",
    "    # Translate bounding box\n",
    "    bbox_original = bbox / resize_scale + crop_box[0]\n",
    "\n",
    "    return bbox_original.reshape((4,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ignore Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_boxes(fbf_bbox_df, img_height, img_width, score_threshold=0.1, normalize=True):\n",
    "    count_matrix = np.zeros((img_height, img_width))\n",
    "    for frame, df in fbf_bbox_df.groupby(\"frame\"):\n",
    "        tmp_score = np.zeros((img_height, img_width))\n",
    "\n",
    "        for x1, y1, x2, y2, score in df[[\"x1\", \"y1\", \"x2\", \"y2\", \"score\"]].values:\n",
    "            x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
    "\n",
    "            if score > score_threshold:\n",
    "                tmp_score[y1:y2, x1:x2] = np.maximum(score, tmp_score[y1:y2, x1:x2])  # add all the boxes into one image\n",
    "\n",
    "        count_matrix += tmp_score\n",
    "\n",
    "    if normalize:\n",
    "        # scale to [0, 1]\n",
    "        count_matrix = (count_matrix - count_matrix.min()) / (count_matrix.max() - count_matrix.min())\n",
    "    \n",
    "    return count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_regions(mask, area_threshold=2000,):\n",
    "    regions = label(mask, connectivity = 1) # get connected regions\n",
    "    \n",
    "    for region_idx in np.unique(regions):\n",
    "        if region_idx == 0: # 0 is background\n",
    "            continue\n",
    "        \n",
    "        region_mask = regions == region_idx\n",
    "        if region_mask.sum() < area_threshold: # get rid of small regions\n",
    "            mask = np.where(region_mask, False, mask)\n",
    "            \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ignore_mask(frame_by_frame_path, ignore_matrix_path, img_shape, count_threshold=0.08, area_threshold=2000, score_threshold=0.1, gaussian_sigma=3):\n",
    "    # Read in bboxes\n",
    "    fbf_bbox_df = pd.read_csv(frame_by_frame_path)\n",
    "    \n",
    "    # Combine bboxes\n",
    "    heatmap = combine_boxes(fbf_bbox_df, img_shape[0], img_shape[1], score_threshold)\n",
    "    \n",
    "    # Create ignore mask\n",
    "    mask = heatmap > count_threshold\n",
    "    mask = get_connected_regions(mask, area_threshold) \n",
    "    mask = gaussian_filter(mask.astype(float), gaussian_sigma) > count_threshold\n",
    "    \n",
    "    # Save ignore mask\n",
    "    np.save(ignore_matrix_path, mask)\n",
    "    \n",
    "def create_ignore_mask_generator(fbf_results, img_shape, count_threshold=0.08, area_threshold=2000, score_threshold=0.1, gaussian_sigma=3, alpha=0.1):\n",
    "    \"\"\"\n",
    "    Creates a rolling ignore mask, suitable for live processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    running_heatmap = np.zeros(img_shape[:2])\n",
    "    for i, (frame, results) in enumerate(fbf_results):\n",
    "        # Maybe have an alpha like how background images are made?\n",
    "        running_heatmap = combine_boxes(results, img_shape[0], img_shape[1], score_threshold, normalize=False) * alpha + (1 - alpha) * running_heatmap\n",
    "        # Normalise after adding instead of before\n",
    "        heatmap_norm = (running_heatmap - running_heatmap.min()) / (running_heatmap.max() - running_heatmap.min())\n",
    "        \n",
    "        # Create ignore mask\n",
    "        mask = heatmap_norm > count_threshold\n",
    "        mask = get_connected_regions(mask, area_threshold)\n",
    "        mask = gaussian_filter(mask.astype(float), gaussian_sigma) > count_threshold\n",
    "        \n",
    "        yield mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReID Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReidExtractor:\n",
    "    \"\"\"Base feature extractor class.\n",
    "    args:\n",
    "        features: List of features.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, model_path, image_size=320):\n",
    "        model = modeling.build_model(model_name, 2000)\n",
    "        model.cuda()\n",
    "        model = nn.DataParallel(model)\n",
    "        model.load_state_dict(torch.load(model_path), strict=False)\n",
    "        model.eval()\n",
    "        self.extractor = model\n",
    "        self.image_size = image_size\n",
    "        self.transforms = misc.preprocess(misc.normalize_torch, self.image_size)\n",
    "        \n",
    "    \n",
    "    def extract(self, img_numpy, region):\n",
    "        img = PIL.Image.fromarray(img_numpy)\n",
    "        img = img.crop(region)\n",
    "        \n",
    "        model_input = self.transforms(img).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features_after, features_before = self.extractor(model_input.cuda())\n",
    "            \n",
    "        features = prep.normalize(features_before.cpu().data.numpy(), norm=\"l2\").astype(\"float32\")\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_nms(all_results, iou_thresh=0.8):\n",
    "    \"\"\"\n",
    "    Applies Non-maximal Supression to a list of anomalies. Resolves duplicate anomalies.\n",
    "    \n",
    "    all_results: list of anomalies [{\"region\": [x1, y1, x2, y2], \"score\": _, \"start_time\": _, \"end_time\": _}, ...]\n",
    "    iou_thresh: intersection over union threshold to consider anomalies the same.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    anomalies = np.array([[*res[\"region\"], res[\"score\"], res[\"start_time\"], res[\"end_time\"]]\n",
    "                          for res in all_results])\n",
    "    \n",
    "\n",
    "    x1 = anomalies[:, 0]\n",
    "    y1 = anomalies[:, 1]\n",
    "    x2 = anomalies[:, 2]\n",
    "    y2 = anomalies[:, 3]\n",
    "    scores = anomalies[:, 4]\n",
    "    start_time = anomalies[:, 5]\n",
    "    end_time = anomalies[:, 6]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    \n",
    "    order = scores.argsort()[::-1]  # sort by score\n",
    "    keep = []  \n",
    "    while len(order) > 0:   \n",
    "        i = order[0]  \n",
    "        keep.append(i)  \n",
    "        \n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])  # compute IoU\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])  \n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])  \n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])  \n",
    "  \n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)  \n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)  \n",
    "        inter = w * h  \n",
    "        union = areas[i] + areas[order[1:]] - inter\n",
    "        iou = inter / union \n",
    "        \n",
    "        inds = np.where(iou > iou_thresh)[0]  # select overlapping boxes\n",
    "        tmp_order = order[inds + 1]\n",
    "        if len(tmp_order) > 0:\n",
    "            anomalies[i,5] = np.min(start_time[tmp_order]) # take the widest time window\n",
    "            anomalies[i,6] = np.max(end_time[tmp_order])\n",
    "            \n",
    "        inds = np.where(iou <= iou_thresh)[0]  \n",
    "        order = order[inds + 1] \n",
    "        \n",
    "    anomalies = anomalies[keep, :]\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlapping_time(anomaly_results, gap_threshold=1):\n",
    "    \"\"\"\n",
    "    Turns the overlapping anomaly detection results into anomaly event times.\n",
    "    \n",
    "    eg. for anomalies starting/ending at times: (0, 100), (50, 200), (300, 400), (390, 800)\n",
    "        it will return: (0, 200), (300, 800)\n",
    "        \n",
    "        \n",
    "    anomaly_results: DataFrame with columns: \"start_time\", \"end_time\"\n",
    "    gap_threshold: events with gaps less than this are merged into one.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    starts = anomaly_results[\"start_time\"].values\n",
    "    ends = anomaly_results[\"end_time\"].values\n",
    "    \n",
    "    order = starts.argsort() # sort by start time\n",
    "    starts = starts[order]\n",
    "    ends = ends[order]\n",
    "    \n",
    "    events = []\n",
    "    i = 0\n",
    "    while i < len(starts):\n",
    "        event_start = starts[i]\n",
    "        \n",
    "        while i + 1 < len(starts) and starts[i + 1] - ends[i] < gap_threshold: # find the end of the overlap\n",
    "            i += 1\n",
    "        \n",
    "        events.append((event_start, ends[i]))\n",
    "        i += 1\n",
    "    \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(reid_model, img1, img2, region1, region2):\n",
    "    return cosine_similarity(reid_model.extract(img1, region1), \n",
    "                             reid_model.extract(img2, region2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(arr, mask):\n",
    "    \"\"\"\n",
    "    just makes it clear where masking is happening\n",
    "    \n",
    "    arr: np.array of data\n",
    "    mask: boolean np.array with same shape as arr\n",
    "    \"\"\"\n",
    "    \n",
    "    return arr * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_boxes(bboxes, ignore_matrix):\n",
    "    \"\"\"\n",
    "    Creates tmp_score and tmp_detect arrays.\n",
    "    \n",
    "    bboxes: list of bounding boxes and scores [x1, y1, x2, y2, score]\n",
    "    ignore_matrix: Boolean mask of region to ignore for boxes.\n",
    "    \"\"\"\n",
    "    h, w = ignore_matrix.shape\n",
    "    \n",
    "    tmp_score = np.zeros((h,w))\n",
    "    tmp_detect = np.zeros((h,w), dtype=bool)\n",
    "        \n",
    "    for x1, y1, x2, y2, score in bboxes: # for each box\n",
    "        x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
    "\n",
    "        tmp_score[y1:y2, x1:x2] = np.maximum(score, tmp_score[y1:y2, x1:x2]) # add box\n",
    "        tmp_detect[y1:y2, x1:x2] = True\n",
    "\n",
    "    tmp_score = mask(tmp_score, ignore_matrix) # get rid of stuff in ignore regions\n",
    "    tmp_detect &= ignore_matrix\n",
    "    \n",
    "    return tmp_score, tmp_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomalies(video_path, reid_model_path, frame_by_frame_results_path, static_results_path, ignore_matrix_path=None, \n",
    "                  reid_model_name=\"resnet50\", start_frame=1, frame_interval=20, abnormal_duration_thresh=60, detect_thresh=5, \n",
    "                  undetect_thresh=8, score_thresh=0.3, light_thresh=0.8, anomaly_score_thresh=0.7, similarity_thresh=0.95,\n",
    "                  suspicious_time_thresh=18, verbose=False):\n",
    "    \"\"\"\n",
    "    Performs the anomaly detection\n",
    "    \n",
    "    video_path: path to raw video\n",
    "    reid_model_path: path to re-ID model checkpoint\n",
    "    frame_by_frame_results_path: path to object detection results on raw video\n",
    "    static_results_path: path to object detection results on background images\n",
    "    ignore_matrix_path: path to ignore region mask\n",
    "    reid_model_name: backbone used for reid model\n",
    "    start_frame: video frame to start from\n",
    "    frame_interval: interval between frames to do calculations on\n",
    "    abnormal_duration_thresh: duration (in seconds) to consider an object abnormal\n",
    "    detect_thresh: duration (in frames) to consider an object for tracking\n",
    "    undetect_thresh: duration (in frames) to stop considering an object for tracking\n",
    "    score_thresh: detection score threshold for bounding boxes\n",
    "    light_thresh: brightness threshold (not sure what it does)\n",
    "    anomaly_score_thresh: threshold to consider an object an anomaly\n",
    "    similarity_thresh: threshold for object re-ID\n",
    "    suspicious_time_thresh: duration (in seconds) for an object to be considered suspicious\n",
    "    verbose: verbose printing\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Read result data\n",
    "    fbf_bbox_df = pd.read_csv(frame_by_frame_results_path)\n",
    "    static_results_df = pd.read_csv(static_results_path)\n",
    "    \n",
    "    \n",
    "    # Get video data\n",
    "    vid = VideoReader(video_path)\n",
    "    num_frames, framerate, image_shape = vid.nframes, vid.framerate, vid.img_shape\n",
    "    \n",
    "    # load model\n",
    "    reid_model = ReidExtractor(reid_model_name, reid_model_path)\n",
    "    \n",
    "    # Set up information matrices\n",
    "    h, w, _ = image_shape\n",
    "    \n",
    "    if ignore_matrix_path is None:\n",
    "        ignore_matrix = np.ones((h, w), dtype=bool) # Dont ignore anything\n",
    "    else:\n",
    "        ignore_matrix = np.load(ignore_matrix_path).astype(bool)\n",
    "    \n",
    "    detect_count_matrix = np.zeros((h,w))            \n",
    "    undetect_count_matrix = np.zeros((h,w))  \n",
    "    start_time_matrix = np.zeros((h,w))\n",
    "    end_time_matrix = np.zeros((h,w))\n",
    "    score_matrix = np.zeros((h,w))\n",
    "    state_matrix = np.zeros((h,w), dtype=bool)      # State matrix, 0/1 distinguishes suspicious candidate states\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"total frames: {num_frames}, framerate: {framerate}, height: {h}, width: {w}\")\n",
    "        print(\"-------------------------\")\n",
    "    \n",
    "    \n",
    "    ### Main loop\n",
    "    start = False\n",
    "    tmp_start = False\n",
    "    all_results=[]\n",
    "    anomaly_now ={}\n",
    "    for frame in range(start_frame, num_frames, frame_interval):\n",
    "        # create tmp_score, tmp_detect\n",
    "        boxes = static_results_df.loc[(static_results_df[\"score\"] > score_thresh) & \n",
    "                                      (static_results_df[\"frame\"] == frame), \n",
    "                                      [\"x1\", \"y1\", \"x2\", \"y2\", \"score\"]].values\n",
    "\n",
    "        tmp_score, tmp_detect = add_boxes(boxes, ignore_matrix)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"frame: {frame}\")\n",
    "            \n",
    "            if len(boxes) > 0:\n",
    "                print(\"\\tboxes:\", len(boxes))\n",
    "\n",
    "        score_matrix += tmp_score # add running totals\n",
    "        detect_count_matrix += tmp_detect\n",
    "\n",
    "\n",
    "        # Update detection matrices\n",
    "        undetect_count_matrix += ~ tmp_detect\n",
    "        undetect_count_matrix[tmp_detect] = 0\n",
    "\n",
    "        # Update time matrices\n",
    "        start_time_matrix[detect_count_matrix == 1] = -600 if frame == 1 else frame # why -600 for frame 1?\n",
    "        end_time_matrix[detect_count_matrix > 0] = frame\n",
    "\n",
    "        # Update state matrices\n",
    "        state_matrix[detect_count_matrix > detect_thresh] = True\n",
    "\n",
    "        # Detect anomaly\n",
    "        time_delay = mask(end_time_matrix - start_time_matrix, state_matrix)\n",
    "        delay_max_idx = np.unravel_index(time_delay.argmax(), time_delay.shape)\n",
    "        \n",
    "#         print(f\"\\tmax delay: {time_delay.max()}, start: {start_time_matrix[delay_max_idx]}, end: {end_time_matrix[delay_max_idx]}, state: {state_matrix[delay_max_idx]}\")\n",
    "        if not start and time_delay.max() / framerate > abnormal_duration_thresh: # and score_matrix[delay_max_idx]/detect_count_matrix[delay_max_idx]>0.8:\n",
    "            \n",
    "            delay_max_idx = np.unravel_index(time_delay.argmax(), time_delay.shape)\n",
    "\n",
    "            # backtrack the start time\n",
    "            time_frame = int(start_time_matrix[delay_max_idx] / 5) * 5 + 1 # why 5s and 1?\n",
    "\n",
    "            G = np.where(detect_count_matrix < detect_count_matrix[delay_max_idx] - 2, 0, 1) # What does G represent?, why -2?\n",
    "            region = utils.search_region(G, delay_max_idx)\n",
    "\n",
    "            # vehicle reid\n",
    "            if 'start_time' in anomaly_now and (time_frame / framerate - anomaly_now['end_time']) < 30: # why 30?\n",
    "                f1_frame_num = max(1, anomaly_now['start_time'] * framerate)\n",
    "                f2_frame_num = max(1, time_frame)\n",
    "\n",
    "                similarity = get_similarity(reid_model, vid.get_frame(f1_frame_num), vid.get_frame(f2_frame_num), anomaly_now[\"region\"], region)\n",
    "\n",
    "                if similarity > similarity_thresh:\n",
    "                    time_frame = int(anomaly_now['start_time'] * framerate / 5) * 5 + 1 # why 5s and 1?\n",
    "                else:\n",
    "                    anomaly_now['region'] = region\n",
    "\n",
    "            else: \n",
    "                anomaly_now['region'] = region\n",
    "\n",
    "\n",
    "            # IoU stuff\n",
    "            max_iou = 1\n",
    "            count = 1\n",
    "            start_time = time_frame\n",
    "            tmp_len = 1\n",
    "#             raio = 1\n",
    "            while (max_iou > 0.1 or tmp_len < 40 or raio > 0.6) and time_frame > 1: # why 0.1, 40, 0.6?\n",
    "                raio = count / tmp_len\n",
    "\n",
    "                if time_frame in fbf_bbox_df.frame:\n",
    "                    bboxes = fbf_bbox_df.loc[fbf_bbox_df.frame == time_frame, [\"x1\", \"y1\", \"x2\", \"y2\", \"score\"]].values\n",
    "                    max_iou = utils.compute_iou(anomaly_now['region'], bboxes)\n",
    "\n",
    "                else:\n",
    "                    max_iou = 0\n",
    "\n",
    "                time_frame -= 5 # why 5?\n",
    "                if max_iou > 0.3: # why 0.3?\n",
    "                    count += 1\n",
    "                    if max_iou > 0.5: # why 0.5?  # they mention 0.5 IoU in the paper for NMS, might not be this \n",
    "                        start_time = time_frame\n",
    "\n",
    "                tmp_len += 1\n",
    "\n",
    "\n",
    "            # back track start_time, until brightness at that spot falls below a threshold\n",
    "            for time_frame in range(start_time, 1, -5):\n",
    "#                 print(f\"\\ttimeframe: {time_frame}\")\n",
    "                tmp_im = vid.get_frame(time_frame)\n",
    "                if utils.compute_brightness(tmp_im[region[1]:region[3], region[0]:region[2]]) <= light_thresh:\n",
    "                    break\n",
    "\n",
    "                start_time = time_frame\n",
    "\n",
    "\n",
    "            anomaly_now['start_time'] = max(0, start_time / framerate)\n",
    "            anomaly_now['end_time'] = max(0, end_time_matrix[delay_max_idx] / framerate)\n",
    "            start = True\n",
    "\n",
    "\n",
    "\n",
    "        elif not tmp_start and time_delay.max() > suspicious_time_thresh * framerate:\n",
    "            time_frame = start_time_matrix[delay_max_idx]\n",
    "\n",
    "            G = np.where(detect_count_matrix < detect_count_matrix[delay_max_idx] - 2, 0, 1) # what does G represent?\n",
    "            region = utils.search_region(G, delay_max_idx)\n",
    "\n",
    "\n",
    "            # vehicle reid\n",
    "            if 'start_time' in anomaly_now and (time_frame / framerate - anomaly_now['end_time']) < 30: # why 30?\n",
    "                f1_frame_num = max(1, anomaly_now['start_time'] * framerate)\n",
    "                f2_frame_num = max(1, time_frame)\n",
    "\n",
    "                similarity = get_similarity(reid_model, vid.get_frame(f1_frame_num), vid.get_frame(f2_frame_num), anomaly_now[\"region\"], region)\n",
    "\n",
    "                if similarity > similarity_thresh:\n",
    "                    time_frame = int(anomaly_now['start_time'] * framerate / 5) * 5 + 1\n",
    "                    region = anomaly_now['region']\n",
    "\n",
    "            anomaly_now['region'] = region\n",
    "            anomaly_now['start_time'] = max(0, time_frame / framerate)\n",
    "            anomaly_now['end_time'] = max(0, end_time_matrix[delay_max_idx] / framerate)\n",
    "\n",
    "            tmp_start = True\n",
    "\n",
    "\n",
    "        if start and time_delay.max() / framerate > abnormal_duration_thresh:\n",
    "\n",
    "            delay_max_idx = np.unravel_index(time_delay.argmax(), time_delay.shape)\n",
    "\n",
    "            if undetect_count_matrix[delay_max_idx] > undetect_thresh:\n",
    "                anomaly_score = score_matrix[delay_max_idx] / detect_count_matrix[delay_max_idx]\n",
    "                \n",
    "                print(\"\\t\", anomaly_now, anomaly_score)\n",
    "                if anomaly_score > anomaly_score_thresh:\n",
    "                    anomaly_now['end_time'] = end_time_matrix[delay_max_idx] / framerate\n",
    "                    anomaly_now['score'] = anomaly_score\n",
    "\n",
    "                    all_results.append(anomaly_now)\n",
    "                    anomaly_now = {}\n",
    "\n",
    "                start = False\n",
    "\n",
    "\n",
    "        elif tmp_start and time_delay.max() > suspicious_time_thresh * framerate:\n",
    "            if undetect_count_matrix[delay_max_idx] > undetect_thresh:\n",
    "\n",
    "                anomaly_score = score_matrix[delay_max_idx] / detect_count_matrix[delay_max_idx]\n",
    "                if anomaly_score > anomaly_score_thresh:\n",
    "                    anomaly_now['end_time'] = end_time_matrix[delay_max_idx] / framerate\n",
    "                    anomaly_now['score'] = anomaly_score\n",
    "\n",
    "                tmp_start = False\n",
    "\n",
    "        # undetect matrix change state_matrix\n",
    "        state_matrix[undetect_count_matrix > undetect_thresh] = False\n",
    "        undetect_count_matrix[undetect_count_matrix > undetect_thresh] = 0\n",
    "\n",
    "        # update matrix\n",
    "        tmp_detect |= state_matrix\n",
    "        detect_count_matrix = mask(detect_count_matrix, tmp_detect)\n",
    "        score_matrix = mask(score_matrix, tmp_detect)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Add all anomalies to the results list\n",
    "    print(\"---\", start, time_delay.max(), score_matrix[delay_max_idx], detect_count_matrix[delay_max_idx])\n",
    "    if start and time_delay.max() > abnormal_duration_thresh * framerate:\n",
    "        anomaly_score = score_matrix[delay_max_idx] / detect_count_matrix[delay_max_idx]\n",
    "        if anomaly_score > anomaly_score_thresh:\n",
    "            anomaly_now['end_time'] = end_time_matrix[delay_max_idx] / framerate\n",
    "            anomaly_now['score'] = anomaly_score\n",
    "\n",
    "            all_results.append(anomaly_now)\n",
    "            anomaly_now = {}\n",
    "            start = False\n",
    "            \n",
    "    \n",
    "    # Apply Non-Maximal Supression to the results\n",
    "    if all_results:\n",
    "        nms_out = anomaly_nms(all_results)\n",
    "\n",
    "#         final_result = {'start_time': 892, 'score': 0} # why 892?\n",
    "#         for nms_start_time, nms_end_time in nms_out[:, 5:7]:\n",
    "#             if nms_start_time < final_result[\"start_time\"]:\n",
    "#                 final_result[\"start_time\"] = max(0, int(nms_start_time - 1))\n",
    "#                 final_result[\"score\"] = 1\n",
    "#                 final_result[\"end_time\"] = nms_end_time\n",
    "                \n",
    "        final_results = pd.DataFrame(nms_out, columns=[\"x1\", \"y1\", \"x2\", \"y2\", \"score\", \"start_time\", \"end_time\"])\n",
    "\n",
    "        return final_results\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsDict(OrderedDict):\n",
    "    \"\"\"\n",
    "    Accumulates detection results as they are generated.\n",
    "    \n",
    "    results_gen: Generator that yields (key, results) pairs\n",
    "    args, kwargs: extra arguments to pass to the dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, results_gen, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.results_gen = results_gen\n",
    "        self.max_frame = -1\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Retrieve the results for given key.\n",
    "        If the key is not in the dictionary, generate results up to the key (frame).\n",
    "        Returns None if the frame is not produced from the generator\n",
    "        \"\"\"\n",
    "        assert type(key) == int  # only support integer frame number for now\n",
    "        \n",
    "        if key in self:\n",
    "            return super().__getitem__(key)\n",
    "        \n",
    "        else:\n",
    "            # Generate new results\n",
    "            while self.max_frame < key:\n",
    "                frame, results = next(self.results_gen)\n",
    "                print(\"generated:\", frame)\n",
    "                self[frame] = results\n",
    "                \n",
    "            if key not in self:\n",
    "                print(\"Key not found:\", key)\n",
    "                return None\n",
    "#                 raise KeyError\n",
    "            \n",
    "    def __setitem__(self, key, value):\n",
    "        super().__setitem__(key, value)\n",
    "        self.max_frame = max(key, self.max_frame)\n",
    "        \n",
    "    def iterator(self):\n",
    "        \"\"\"\n",
    "        Returns an iterator over all items, generates new results too.\n",
    "        \"\"\"\n",
    "        \n",
    "        for key, value in self.items():\n",
    "            yield key, value\n",
    "            \n",
    "        for frame, results in self.results_gen:\n",
    "            print(\"generated:\", frame)\n",
    "            self[frame] = results\n",
    "            yield frame, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomalies_sequential(video_reader, reid_model_path, fbf_results_dict, static_results_dict, ignore_matrix_gen=None, \n",
    "                  reid_model_name=\"resnet50\", start_frame=1, frame_interval=20, abnormal_duration_thresh=60, detect_thresh=5, \n",
    "                  undetect_thresh=8, score_thresh=0.3, light_thresh=0.8, anomaly_score_thresh=0.7, similarity_thresh=0.95,\n",
    "                  suspicious_time_thresh=18, verbose=False):\n",
    "    \"\"\"\n",
    "    Performs the anomaly detection. Sequential version\n",
    "    \n",
    "    video_reader: VideoReader object for raw video\n",
    "    reid_model_path: path to re-ID model checkpoint\n",
    "    fbf_results_dict: ResultsDict object for frame-by-frame/raw video detection results\n",
    "    static_results_dict: ResultsDict object for static/background detection results\n",
    "    ignore_matrix_gen: generator yielding ignore matrix, must have the same interval as frame_interval\n",
    "    reid_model_name: backbone used for reid model\n",
    "    start_frame: video frame to start from\n",
    "    frame_interval: interval between frames to do calculations on\n",
    "    abnormal_duration_thresh: duration (in seconds) to consider an object abnormal\n",
    "    detect_thresh: duration (in frames) to consider an object for tracking\n",
    "    undetect_thresh: duration (in frames) to stop considering an object for tracking\n",
    "    score_thresh: detection score threshold for bounding boxes\n",
    "    light_thresh: brightness threshold (not sure what it does)\n",
    "    anomaly_score_thresh: threshold to consider an object an anomaly\n",
    "    similarity_thresh: threshold for object re-ID\n",
    "    suspicious_time_thresh: duration (in seconds) for an object to be considered suspicious\n",
    "    verbose: verbose printing\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get video data\n",
    "    vid = video_reader\n",
    "    num_frames, framerate, image_shape = vid.nframes, vid.framerate, vid.img_shape\n",
    "    \n",
    "    # load model\n",
    "    reid_model = ReidExtractor(reid_model_name, reid_model_path)\n",
    "    \n",
    "    # Set up information matrices\n",
    "    h, w, _ = image_shape\n",
    "    \n",
    "    if ignore_matrix_gen is None:\n",
    "        ign = np.ones((h, w), dtype=bool) # Dont ignore anything, \n",
    "        ignore_matrix_gen = (ign for _ in iter(int, 1)) # infinite generator\n",
    "    \n",
    "    detect_count_matrix = np.zeros((h,w))            \n",
    "    undetect_count_matrix = np.zeros((h,w))  \n",
    "    start_time_matrix = np.zeros((h,w))\n",
    "    end_time_matrix = np.zeros((h,w))\n",
    "    score_matrix = np.zeros((h,w))\n",
    "    state_matrix = np.zeros((h,w), dtype=bool)      # State matrix, 0/1 distinguishes suspicious candidate states\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"total frames: {num_frames}, framerate: {framerate}, height: {h}, width: {w}\")\n",
    "        print(\"-------------------------\")\n",
    "    \n",
    "    \n",
    "    ### Main loop\n",
    "    start = False\n",
    "    tmp_start = False\n",
    "    all_results=[]\n",
    "    anomaly_now ={}\n",
    "    for frame in range(start_frame, num_frames, frame_interval):\n",
    "        ignore_matrix = next(ignore_matrix_gen)\n",
    "        \n",
    "        # create tmp_score, tmp_detect\n",
    "        static_results = static_results_dict[frame]\n",
    "        if static_results is not None:\n",
    "            boxes = static_results.loc[static_results[\"score\"] > score_thresh, \n",
    "                                       [\"x1\", \"y1\", \"x2\", \"y2\", \"score\"]].values\n",
    "        else:\n",
    "            boxes = []\n",
    "\n",
    "        tmp_score, tmp_detect = add_boxes(boxes, ignore_matrix)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"frame: {frame}\")\n",
    "            \n",
    "            if len(boxes) > 0:\n",
    "                print(\"\\tboxes:\", len(boxes))\n",
    "\n",
    "        score_matrix += tmp_score # add running totals\n",
    "        detect_count_matrix += tmp_detect\n",
    "\n",
    "\n",
    "        # Update detection matrices\n",
    "        undetect_count_matrix += ~ tmp_detect\n",
    "        undetect_count_matrix[tmp_detect] = 0\n",
    "\n",
    "        # Update time matrices\n",
    "        start_time_matrix[detect_count_matrix == 1] = -600 if frame == 1 else frame # why -600 for frame 1?\n",
    "        end_time_matrix[detect_count_matrix > 0] = frame\n",
    "\n",
    "        # Update state matrices\n",
    "        state_matrix[detect_count_matrix > detect_thresh] = True\n",
    "\n",
    "        # Detect anomaly\n",
    "        time_delay = mask(end_time_matrix - start_time_matrix, state_matrix)\n",
    "        delay_max_idx = np.unravel_index(time_delay.argmax(), time_delay.shape)\n",
    "        \n",
    "#         print(f\"\\tmax delay: {time_delay.max()}, start: {start_time_matrix[delay_max_idx]}, end: {end_time_matrix[delay_max_idx]}, state: {state_matrix[delay_max_idx]}\")\n",
    "        if not start and time_delay.max() / framerate > abnormal_duration_thresh: # and score_matrix[delay_max_idx]/detect_count_matrix[delay_max_idx]>0.8:\n",
    "            \n",
    "            delay_max_idx = np.unravel_index(time_delay.argmax(), time_delay.shape)\n",
    "\n",
    "            # backtrack the start time\n",
    "            time_frame = int(start_time_matrix[delay_max_idx] / 5) * 5 + 1 # why 5s and 1?\n",
    "\n",
    "            G = np.where(detect_count_matrix < detect_count_matrix[delay_max_idx] - 2, 0, 1) # What does G represent?, why -2?\n",
    "            region = utils.search_region(G, delay_max_idx)\n",
    "\n",
    "            # vehicle reid\n",
    "            if 'start_time' in anomaly_now and (time_frame / framerate - anomaly_now['end_time']) < 30: # why 30?\n",
    "                f1_frame_num = max(1, anomaly_now['start_time'] * framerate)\n",
    "                f2_frame_num = max(1, time_frame)\n",
    "\n",
    "                similarity = get_similarity(reid_model, vid.get_frame(f1_frame_num), vid.get_frame(f2_frame_num), anomaly_now[\"region\"], region)\n",
    "\n",
    "                if similarity > similarity_thresh:\n",
    "                    time_frame = int(anomaly_now['start_time'] * framerate / 5) * 5 + 1 # why 5s and 1?\n",
    "                else:\n",
    "                    anomaly_now['region'] = region\n",
    "\n",
    "            else: \n",
    "                anomaly_now['region'] = region\n",
    "\n",
    "\n",
    "            # IoU stuff\n",
    "            max_iou = 1\n",
    "            count = 1\n",
    "            start_time = time_frame\n",
    "            tmp_len = 1\n",
    "#             raio = 1\n",
    "            while (max_iou > 0.1 or tmp_len < 40 or raio > 0.6) and time_frame > 1: # why 0.1, 40, 0.6?\n",
    "                raio = count / tmp_len\n",
    "\n",
    "                fbf_results = fbf_results_dict[time_frame]\n",
    "                if fbf_results is not None:\n",
    "                    bboxes = fbf_results[[\"x1\", \"y1\", \"x2\", \"y2\", \"score\"]].values\n",
    "                    max_iou = utils.compute_iou(anomaly_now['region'], bboxes)\n",
    "\n",
    "                else:\n",
    "                    max_iou = 0\n",
    "\n",
    "                time_frame -= 5 # why 5?\n",
    "                if max_iou > 0.3: # why 0.3?\n",
    "                    count += 1\n",
    "                    if max_iou > 0.5: # why 0.5?  # they mention 0.5 IoU in the paper for NMS, might not be this \n",
    "                        start_time = time_frame\n",
    "\n",
    "                tmp_len += 1\n",
    "\n",
    "\n",
    "            # back track start_time, until brightness at that spot falls below a threshold\n",
    "            for time_frame in range(start_time, 1, -5):\n",
    "#                 print(f\"\\ttimeframe: {time_frame}\")\n",
    "                tmp_im = vid.get_frame(time_frame)\n",
    "                if utils.compute_brightness(tmp_im[region[1]:region[3], region[0]:region[2]]) <= light_thresh:\n",
    "                    break\n",
    "\n",
    "                start_time = time_frame\n",
    "\n",
    "\n",
    "            anomaly_now['start_time'] = max(0, start_time / framerate)\n",
    "            anomaly_now['end_time'] = max(0, end_time_matrix[delay_max_idx] / framerate)\n",
    "            start = True\n",
    "\n",
    "\n",
    "\n",
    "        elif not tmp_start and time_delay.max() > suspicious_time_thresh * framerate:\n",
    "            time_frame = start_time_matrix[delay_max_idx]\n",
    "\n",
    "            G = np.where(detect_count_matrix < detect_count_matrix[delay_max_idx] - 2, 0, 1) # what does G represent?\n",
    "            region = utils.search_region(G, delay_max_idx)\n",
    "\n",
    "\n",
    "            # vehicle reid\n",
    "            if 'start_time' in anomaly_now and (time_frame / framerate - anomaly_now['end_time']) < 30: # why 30?\n",
    "                f1_frame_num = max(1, anomaly_now['start_time'] * framerate)\n",
    "                f2_frame_num = max(1, time_frame)\n",
    "\n",
    "                similarity = get_similarity(reid_model, vid.get_frame(f1_frame_num), vid.get_frame(f2_frame_num), anomaly_now[\"region\"], region)\n",
    "\n",
    "                if similarity > similarity_thresh:\n",
    "                    time_frame = int(anomaly_now['start_time'] * framerate / 5) * 5 + 1\n",
    "                    region = anomaly_now['region']\n",
    "\n",
    "            anomaly_now['region'] = region\n",
    "            anomaly_now['start_time'] = max(0, time_frame / framerate)\n",
    "            anomaly_now['end_time'] = max(0, end_time_matrix[delay_max_idx] / framerate)\n",
    "\n",
    "            tmp_start = True\n",
    "\n",
    "\n",
    "        if start and time_delay.max() / framerate > abnormal_duration_thresh:\n",
    "\n",
    "            delay_max_idx = np.unravel_index(time_delay.argmax(), time_delay.shape)\n",
    "\n",
    "            if undetect_count_matrix[delay_max_idx] > undetect_thresh:\n",
    "                anomaly_score = score_matrix[delay_max_idx] / detect_count_matrix[delay_max_idx]\n",
    "                \n",
    "                print(\"\\t\", anomaly_now, anomaly_score)\n",
    "                if anomaly_score > anomaly_score_thresh:\n",
    "                    anomaly_now['end_time'] = end_time_matrix[delay_max_idx] / framerate\n",
    "                    anomaly_now['score'] = anomaly_score\n",
    "\n",
    "                    all_results.append(anomaly_now)\n",
    "                    anomaly_now = {}\n",
    "\n",
    "                start = False\n",
    "\n",
    "\n",
    "        elif tmp_start and time_delay.max() > suspicious_time_thresh * framerate:\n",
    "            if undetect_count_matrix[delay_max_idx] > undetect_thresh:\n",
    "\n",
    "                anomaly_score = score_matrix[delay_max_idx] / detect_count_matrix[delay_max_idx]\n",
    "                if anomaly_score > anomaly_score_thresh:\n",
    "                    anomaly_now['end_time'] = end_time_matrix[delay_max_idx] / framerate\n",
    "                    anomaly_now['score'] = anomaly_score\n",
    "\n",
    "                tmp_start = False\n",
    "\n",
    "        # undetect matrix change state_matrix\n",
    "        state_matrix[undetect_count_matrix > undetect_thresh] = False\n",
    "        undetect_count_matrix[undetect_count_matrix > undetect_thresh] = 0\n",
    "\n",
    "        # update matrix\n",
    "        tmp_detect |= state_matrix\n",
    "        detect_count_matrix = mask(detect_count_matrix, tmp_detect)\n",
    "        score_matrix = mask(score_matrix, tmp_detect)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Add all anomalies to the results list\n",
    "    print(\"---\", start, time_delay.max(), score_matrix[delay_max_idx], detect_count_matrix[delay_max_idx])\n",
    "    if start and time_delay.max() > abnormal_duration_thresh * framerate:\n",
    "        anomaly_score = score_matrix[delay_max_idx] / detect_count_matrix[delay_max_idx]\n",
    "        if anomaly_score > anomaly_score_thresh:\n",
    "            anomaly_now['end_time'] = end_time_matrix[delay_max_idx] / framerate\n",
    "            anomaly_now['score'] = anomaly_score\n",
    "\n",
    "            all_results.append(anomaly_now)\n",
    "            anomaly_now = {}\n",
    "            start = False\n",
    "            \n",
    "    \n",
    "    # Apply Non-Maximal Supression to the results\n",
    "    if all_results:\n",
    "        nms_out = anomaly_nms(all_results)\n",
    "\n",
    "#         final_result = {'start_time': 892, 'score': 0} # why 892?\n",
    "#         for nms_start_time, nms_end_time in nms_out[:, 5:7]:\n",
    "#             if nms_start_time < final_result[\"start_time\"]:\n",
    "#                 final_result[\"start_time\"] = max(0, int(nms_start_time - 1))\n",
    "#                 final_result[\"score\"] = 1\n",
    "#                 final_result[\"end_time\"] = nms_end_time\n",
    "                \n",
    "        final_results = pd.DataFrame(nms_out, columns=[\"x1\", \"y1\", \"x2\", \"y2\", \"score\", \"start_time\", \"end_time\"])\n",
    "\n",
    "        return final_results\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Running everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_run_single(video_id, video_dir, static_dir, frame_by_frame_results_dir, static_results_dir, crop_boxes_dir, \n",
    "                    ignore_mask_dir, detector_config_path, detector_model_path, reid_model_path, reid_model_backbone,\n",
    "                    crop_results_dir, anomaly_results_dir,\n",
    "                    bg_interval=4, bg_alpha=0.05, bg_start_frame=1, bg_threshold=5, raw_detect_interval=30, \n",
    "                    crop_min_obj_size=8, crop_row_capacity=3, crop_box_aspect_ratio=2,\n",
    "                    ignore_count_thresh=0.08, ignore_area_thresh=2000, ignore_score_thresh=0.1, ignore_gau_sigma=3,\n",
    "                    abnormal_duration_thresh=60, detect_duration_thresh=6, undetect_duration_thresh=8, bbox_score_thresh=0.3,\n",
    "                    light_thresh=0.8, anomaly_thresh=0.8, similarity_thresh=0.95, suspicious_duration_thresh=18,\n",
    "                    detector_verbose_interval=20, verbose=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Runs the full anomaly detection pipeline on a video\n",
    "    \n",
    "    video_id: video id/name\n",
    "    video_dir: folder the video is in\n",
    "    static_dir: folder to put the background images in\n",
    "    frame_by_frame_results_dir: folder to put the raw video detection results in\n",
    "    static_results_dir: folder to put the background image detection results in\n",
    "    crop_boxes_dir: folder to put the crop boxes in\n",
    "    ignore_mask_dir: folder to put the ignore region mask in\n",
    "    \n",
    "    detector_config_path: path to detector configuration file\n",
    "    detector_model_path: path to detector model checkpoint\n",
    "    reid_model_path: path to re-ID model checkpoint\n",
    "    reid_model_backbone: re-ID model backbone. eg. \"resnet50\"\n",
    "    \n",
    "    bg_interval, bg_alpha, bg_start_frame, bg_threshold: see calc_bg_full_video function\n",
    "    raw_detect_interval: number of frames between detection on raw video\n",
    "    crop_min_obj_size, crop_row_capacity, crop_box_aspect_ratio: see create_crop_boxes function\n",
    "    ignore_count_thresh, ignore_area_thresh, ignore_score_thresh, ignore_gau_sigma: see create_ignore_mask function\n",
    "    abnormal_duration_thresh, detect_duration_thresh, undetect_duration_thresh, bbox_score_thresh,\n",
    "        light_thresh, anomaly_thresh, similarity_thresh, suspicious_duration_thresh:\n",
    "            See get_anomalies function\n",
    "    \n",
    "    detector_verbose_interval: detector progress printing interval\n",
    "    verbose: verbose printing\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Set up file paths\n",
    "    video_path = os.path.join(video_dir, f\"{video_id}.mp4\")\n",
    "    static_images_folder = os.path.join(static_dir, f\"{video_id}\")\n",
    "    fbf_results_path = os.path.join(frame_by_frame_results_dir, f\"{video_id}.csv\")\n",
    "    static_results_path = os.path.join(static_results_dir, f\"{video_id}.csv\")\n",
    "    crop_boxes_path = os.path.join(crop_boxes_dir, f\"{video_id}.csv\")\n",
    "    crop_results_path = os.path.join(crop_results_dir, f\"{video_id}.csv\")\n",
    "    ignore_mask_path = os.path.join(ignore_mask_dir, f\"{video_id}.npy\")\n",
    "    anomaly_results_path = os.path.join(anomaly_results_dir, f\"{video_id}.csv\")\n",
    "    \n",
    "    # Create folders\n",
    "    os.makedirs(static_images_folder, exist_ok=True)\n",
    "    os.makedirs(frame_by_frame_results_dir, exist_ok=True)\n",
    "    os.makedirs(static_results_dir, exist_ok=True)\n",
    "    os.makedirs(crop_boxes_dir, exist_ok=True)\n",
    "    os.makedirs(crop_results_dir, exist_ok=True)\n",
    "    os.makedirs(ignore_mask_dir, exist_ok=True)\n",
    "    os.makedirs(anomaly_results_dir, exist_ok=True)\n",
    "    \n",
    "    # Read Video\n",
    "    raw_video = VideoReader(video_path)\n",
    "    \n",
    "#     # bg modeling\n",
    "#     print(\"Creating background...\")\n",
    "#     calc_bg_full_video(video_path, static_images_folder, bg_interval, bg_alpha, bg_start_frame, bg_threshold, verbose)\n",
    "    \n",
    "#     # Detection\n",
    "#     detector = Detector(detector_config_path, detector_model_path, detector_verbose_interval)\n",
    "#     ## Raw Video\n",
    "#     print(\"Detecting raw video...\")\n",
    "#     raw_images, raw_frame_nums = raw_video.load_video(raw_detect_interval)\n",
    "#     fbf_results = detector.detect_images(raw_images, raw_frame_nums)\n",
    "#     fbf_results.to_csv(fbf_results_path, index=False)\n",
    "    \n",
    "    \n",
    "#     ## Static Images\n",
    "#     static_reader = ImageReader(static_images_folder)\n",
    "#     static_frame_names = list(map(lambda f: int(f[:-4]), static_reader.filenames)) # \"123.jpg\" -> 123\n",
    "    \n",
    "#     print(\"Detecting background...\")\n",
    "#     static_results = detector.detect_images(static_reader.load_images(), static_frame_names)\n",
    "#     static_results.to_csv(static_results_path, index=False)\n",
    "    \n",
    "    \n",
    "    # Perspective Cropping\n",
    "#     print(\"Creating crop boxes...\")\n",
    "#     create_crop_boxes(fbf_results_path, crop_boxes_path, raw_video.img_shape, crop_min_obj_size, crop_row_capacity, crop_box_aspect_ratio) # either static/fbf results should work\n",
    "    \n",
    "    \n",
    "    # Should be able to use this in place of normal static images. Doesnt look feasable atm, way too long detection time\n",
    "#     crop_boxes = pd.read_csv(crop_boxes_path).values\n",
    "#     print(\"Detecting cropped background...\") \n",
    "#     crop_detect_results = detector.detect_images(static_reader.load_images(), static_frame_names, crop_boxes=crop_boxes)\n",
    "#     crop_detect_results.to_csv(crop_results_path)\n",
    "\n",
    "    \n",
    "#     # Ignore Region\n",
    "    print(\"Creating ingore mask...\")\n",
    "#     create_ignore_mask(fbf_results_path, ignore_mask_path, raw_video.img_shape, ignore_count_thresh, ignore_area_thresh, ignore_score_thresh, ignore_gau_sigma)\n",
    "    \n",
    "    # Detect anomalies\n",
    "    print(\"Detecting anomalies...\")\n",
    "    anomalies = get_anomalies(video_path, reid_model_path, fbf_results_path, static_results_path, ignore_mask_path, \n",
    "                              reid_model_backbone, bg_start_frame, bg_interval, abnormal_duration_thresh, detect_duration_thresh, \n",
    "                              undetect_duration_thresh, bbox_score_thresh, light_thresh, anomaly_thresh, \n",
    "                              similarity_thresh, suspicious_duration_thresh, verbose)\n",
    "    \n",
    "    if anomalies is not None:\n",
    "        anomaly_event_times = get_overlapping_time(anomalies)\n",
    "    \n",
    "        # Save results\n",
    "        print(\"Saving Results...\")\n",
    "        anomalies.to_csv(anomaly_results_path, index=False)\n",
    "\n",
    "        return anomalies, anomaly_event_times\n",
    "    \n",
    "    else:\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_run_sequential(video_id, video_dir, static_dir, frame_by_frame_results_dir, static_results_dir, crop_boxes_dir, \n",
    "                    ignore_mask_dir, detector_config_path, detector_model_path, reid_model_path, reid_model_backbone,\n",
    "                    crop_results_dir, anomaly_results_dir,\n",
    "                    bg_interval=4, bg_alpha=0.05, bg_start_frame=1, bg_threshold=5, raw_detect_interval=30, \n",
    "                    crop_min_obj_size=8, crop_row_capacity=3, crop_box_aspect_ratio=2,\n",
    "                    ignore_count_thresh=0.08, ignore_area_thresh=2000, ignore_score_thresh=0.1, ignore_gau_sigma=3,\n",
    "                    abnormal_duration_thresh=60, detect_duration_thresh=6, undetect_duration_thresh=8, bbox_score_thresh=0.3,\n",
    "                    light_thresh=0.8, anomaly_thresh=0.8, similarity_thresh=0.95, suspicious_duration_thresh=18,\n",
    "                    detector_verbose_interval=20, verbose=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Full run but runs one frame at a time. This should be more suitable for live processing.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up file paths\n",
    "    video_path = os.path.join(video_dir, f\"{video_id}.mp4\")\n",
    "    static_images_folder = os.path.join(static_dir, f\"{video_id}\")\n",
    "    fbf_results_path = os.path.join(frame_by_frame_results_dir, f\"{video_id}.csv\")\n",
    "    static_results_path = os.path.join(static_results_dir, f\"{video_id}.csv\")\n",
    "    crop_boxes_path = os.path.join(crop_boxes_dir, f\"{video_id}.csv\")\n",
    "    crop_results_path = os.path.join(crop_results_dir, f\"{video_id}.csv\")\n",
    "    ignore_mask_path = os.path.join(ignore_mask_dir, f\"{video_id}.npy\")\n",
    "    anomaly_results_path = os.path.join(anomaly_results_dir, f\"{video_id}.csv\")\n",
    "    \n",
    "    # Create folders\n",
    "    os.makedirs(static_images_folder, exist_ok=True)\n",
    "    os.makedirs(frame_by_frame_results_dir, exist_ok=True)\n",
    "    os.makedirs(static_results_dir, exist_ok=True)\n",
    "    os.makedirs(crop_boxes_dir, exist_ok=True)\n",
    "    os.makedirs(crop_results_dir, exist_ok=True)\n",
    "    os.makedirs(ignore_mask_dir, exist_ok=True)\n",
    "    os.makedirs(anomaly_results_dir, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    # Read Video\n",
    "    raw_video = VideoReader(video_path)\n",
    "    \n",
    "    # bg modeling\n",
    "    print(\"Creating background...\")\n",
    "#     bg_images = calc_background(raw_video.load_video()[0], bg_interval, bg_alpha, bg_start_frame, bg_threshold)\n",
    "    bg_images = calc_bg_tensor(raw_video.load_video()[0], bg_interval, bg_alpha, bg_start_frame, bg_threshold)\n",
    "    bg_images = (img for img, _ in bg_images) # throw out frame\n",
    "    \n",
    "    # Detection\n",
    "    detector = Detector(detector_config_path, detector_model_path, detector_verbose_interval)\n",
    "    ## Raw Video\n",
    "    print(\"Detecting raw video...\")\n",
    "    raw_images, raw_frame_nums = raw_video.load_video(raw_detect_interval)\n",
    "    fbf_results_gen = detector.detect_images_generator(raw_images, raw_frame_nums)\n",
    "    fbf_results = ResultsDict(fbf_results_gen)\n",
    "    \n",
    "    \n",
    "    print(\"Detecting background...\")\n",
    "    static_results_gen = detector.detect_images_generator(bg_images, range(bg_start_frame, raw_video.nframes, bg_interval))\n",
    "    static_results = ResultsDict(static_results_gen)\n",
    "    \n",
    "    # Ignore Region\n",
    "    print(\"Creating ingore mask...\")\n",
    "    ignore_alpha = 0.1\n",
    "    ignore_alpha_2 = 1 - (1 - ignore_alpha) ** bg_interval # adjusted for different intervals\n",
    "    ignore_mask_gen = create_ignore_mask_generator(static_results.iterator(), raw_video.img_shape, ignore_count_thresh, ignore_area_thresh, ignore_score_thresh, ignore_gau_sigma, alpha=ignore_alpha_2)\n",
    "    \n",
    "    \n",
    "    for i in range(1000):\n",
    "        next(ignore_mask_gen)\n",
    "        \n",
    "    \n",
    "    \n",
    "#     anomalies = get_anomalies_sequential(raw_video, reid_model_path, fbf_results, static_results, ignore_mask_gen,\n",
    "#                         reid_model_backbone, bg_start_frame, bg_interval, abnormal_duration_thresh, detect_duration_thresh, \n",
    "#                         undetect_duration_thresh, bbox_score_thresh, light_thresh, anomaly_thresh, \n",
    "#                         similarity_thresh, suspicious_duration_thresh, verbose)\n",
    "    \n",
    "    pd.concat(static_results.values()).to_csv(\"/data/tmp/static.csv\", index=False)\n",
    "    pd.concat(fbf_results.values()).to_csv(\"/data/tmp/fbf.csv\", index=False)\n",
    "    \n",
    "    if anomalies is not None:\n",
    "        anomaly_event_times = get_overlapping_time(anomalies)\n",
    "    \n",
    "        # Save results\n",
    "        print(\"Saving Results...\")\n",
    "        anomalies.to_csv(anomaly_results_path, index=False)\n",
    "\n",
    "        return anomalies, anomaly_event_times\n",
    "    \n",
    "    else:\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(video_dir, static_dir, frame_by_frame_results_dir, static_results_dir, crop_boxes_dir, \n",
    "                    ignore_mask_dir, detector_config_path, detector_model_path, reid_model_path, reid_model_backbone,\n",
    "                    crop_results_dir, anomaly_results_dir,\n",
    "                    bg_interval=4, bg_alpha=0.05, bg_start_frame=1, bg_threshold=5, raw_detect_interval=30, \n",
    "                    crop_min_obj_size=8, crop_row_capacity=3, crop_box_aspect_ratio=2,\n",
    "                    ignore_count_thresh=0.08, ignore_area_thresh=2000, ignore_score_thresh=0.1, ignore_gau_sigma=3,\n",
    "                    abnormal_duration_thresh=60, detect_duration_thresh=6, undetect_duration_thresh=8, bbox_score_thresh=0.3,\n",
    "                    light_thresh=0.8, anomaly_thresh=0.8, similarity_thresh=0.95, suspicious_duration_thresh=18,\n",
    "                    detector_verbose_interval=20, verbose=True):\n",
    "    \"\"\"\n",
    "    See full_run_single function for documentation.\n",
    "    \"\"\"\n",
    "    \n",
    "    anomalies_dict, anomaly_times_dict = {}, {}\n",
    "    for filename in sorted(os.listdir(video_dir), key=lambda f: int(f[:-4])):\n",
    "    \n",
    "        video_id = int(filename[:-4])  # \"123.mp4\" -> 123\n",
    "        print(\"Processing video:\", video_id)\n",
    "        \n",
    "        # Sequential by processing steps\n",
    "#         anomalies, anomaly_event_times = full_run_single(video_id, video_dir, static_dir, frame_by_frame_results_dir, static_results_dir, crop_boxes_dir, \n",
    "#                     ignore_mask_dir, detector_config_path, detector_model_path, reid_model_path, reid_model_backbone,\n",
    "#                     crop_results_dir, anomaly_results_dir,\n",
    "#                     bg_interval, bg_alpha, bg_start_frame, bg_threshold, raw_detect_interval, \n",
    "#                     crop_min_obj_size, crop_row_capacity, crop_box_aspect_ratio,\n",
    "#                     ignore_count_thresh, ignore_area_thresh, ignore_score_thresh, ignore_gau_sigma,\n",
    "#                     abnormal_duration_thresh, detect_duration_thresh, undetect_duration_thresh, bbox_score_thresh,\n",
    "#                     light_thresh, anomaly_thresh, similarity_thresh, suspicious_duration_thresh,\n",
    "#                     detector_verbose_interval, verbose)\n",
    "        \n",
    "        # Sequential by frame\n",
    "        anomalies, anomaly_event_times = full_run_sequential(video_id, video_dir, static_dir, frame_by_frame_results_dir, static_results_dir, crop_boxes_dir, \n",
    "                    ignore_mask_dir, detector_config_path, detector_model_path, reid_model_path, reid_model_backbone,\n",
    "                    crop_results_dir, anomaly_results_dir,\n",
    "                    bg_interval, bg_alpha, bg_start_frame, bg_threshold, raw_detect_interval, \n",
    "                    crop_min_obj_size, crop_row_capacity, crop_box_aspect_ratio,\n",
    "                    ignore_count_thresh, ignore_area_thresh, ignore_score_thresh, ignore_gau_sigma,\n",
    "                    abnormal_duration_thresh, detect_duration_thresh, undetect_duration_thresh, bbox_score_thresh,\n",
    "                    light_thresh, anomaly_thresh, similarity_thresh, suspicious_duration_thresh,\n",
    "                    detector_verbose_interval, verbose)\n",
    "    \n",
    "        anomalies_dict[video_id] = anomalies\n",
    "        anomaly_times_dict[video_id] = anomaly_event_times\n",
    "        \n",
    "        print(video_id, anomalies, anomaly_event_times)\n",
    "        \n",
    "        \n",
    "    return anomalies_dict, anomaly_times_dict        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = \"/data/aicity/test\"\n",
    "video_id = 1\n",
    "\n",
    "# todo: create all these in a temp directory\n",
    "static_dir = \"/data/aicity/winner_team/background_images/test\"\n",
    "frame_by_frame_results_dir = \"/data/aicity/winner_team/detection_results/test_framebyframe\"\n",
    "static_results_dir = \"/data/aicity/winner_team/detection_results/test_static\"\n",
    "crop_results_dir = \"/data/aicity/winner_team/detection_results/test_crop\" # todo: add this to program arguments\n",
    "crop_boxes_dir = \"/data/aicity/winner_team/crop_boxes/test\"\n",
    "ignore_mask_dir = \"/data/aicity/winner_team/detection_results/test_seg_masks\"\n",
    "anomaly_results_dir = \"/data/aicity/winner_team/anomaly_results/test\"\n",
    "\n",
    "reid_model_backbone = \"resnet50\"\n",
    "reid_model_path = \"/data/modules/AICity2019_winner/models/reid/reid.pth\"\n",
    "\n",
    "detector_config_path = \"/data/modules/mmdetection/configs/htc/htc_dconv_c3-c5_mstrain_400_1400_x101_64x4d_fpn_20e.py\"\n",
    "detector_model_path = \"/data/modules/mmdetection/checkpoints/htc_dconv_c3-c5_mstrain_400_1400_x101_64x4d_fpn_20e_20190408-0e50669c.pth\"\n",
    "\n",
    "ssd_config_path = \"/data/modules/mmdetection/configs/ssd512_coco_custom.py\"\n",
    "ssd_model_path = \"/data/modules/mmdetection/work_dirs/ssd512_coco/latest.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ingore mask...\n",
      "Detecting anomalies...\n",
      "total frames: 26760, framerate: 30.0, height: 410, width: 800\n",
      "-------------------------\n",
      "frame: 1\n",
      "\tboxes: 8\n",
      "frame: 21\n",
      "\tboxes: 7\n",
      "frame: 41\n",
      "\tboxes: 6\n",
      "frame: 61\n",
      "\tboxes: 7\n",
      "frame: 81\n",
      "\tboxes: 5\n",
      "frame: 101\n",
      "\tboxes: 4\n",
      "frame: 121\n",
      "\tboxes: 3\n",
      "frame: 141\n",
      "\tboxes: 2\n",
      "frame: 161\n",
      "\tboxes: 2\n",
      "frame: 181\n",
      "\tboxes: 1\n",
      "frame: 201\n",
      "\tboxes: 1\n",
      "frame: 221\n",
      "\tboxes: 1\n",
      "frame: 241\n",
      "\tboxes: 1\n",
      "frame: 261\n",
      "\tboxes: 1\n",
      "frame: 281\n",
      "\tboxes: 1\n",
      "frame: 301\n",
      "\tboxes: 1\n",
      "frame: 321\n",
      "\tboxes: 1\n",
      "frame: 341\n",
      "\tboxes: 2\n",
      "frame: 361\n",
      "\tboxes: 2\n",
      "frame: 381\n",
      "\tboxes: 3\n",
      "frame: 401\n",
      "\tboxes: 3\n",
      "frame: 421\n",
      "\tboxes: 3\n",
      "frame: 441\n",
      "\tboxes: 1\n",
      "frame: 461\n",
      "\tboxes: 1\n",
      "frame: 481\n",
      "\tboxes: 1\n",
      "frame: 501\n",
      "\tboxes: 1\n",
      "frame: 521\n",
      "\tboxes: 1\n",
      "frame: 541\n",
      "\tboxes: 1\n",
      "frame: 561\n",
      "\tboxes: 1\n",
      "frame: 581\n",
      "\tboxes: 1\n",
      "frame: 601\n",
      "\tboxes: 1\n",
      "frame: 621\n",
      "\tboxes: 1\n",
      "frame: 641\n",
      "\tboxes: 1\n",
      "frame: 661\n",
      "\tboxes: 1\n",
      "frame: 681\n",
      "\tboxes: 1\n",
      "frame: 701\n",
      "\tboxes: 1\n",
      "frame: 721\n",
      "\tboxes: 1\n",
      "frame: 741\n",
      "\tboxes: 1\n",
      "frame: 761\n",
      "\tboxes: 1\n",
      "frame: 781\n",
      "\tboxes: 1\n",
      "frame: 801\n",
      "\tboxes: 1\n",
      "frame: 821\n",
      "\tboxes: 1\n",
      "frame: 841\n",
      "\tboxes: 1\n",
      "frame: 861\n",
      "\tboxes: 1\n",
      "frame: 881\n",
      "\tboxes: 1\n",
      "frame: 901\n",
      "\tboxes: 1\n",
      "frame: 921\n",
      "\tboxes: 1\n",
      "frame: 941\n",
      "\tboxes: 1\n",
      "frame: 961\n",
      "\tboxes: 2\n",
      "frame: 981\n",
      "\tboxes: 2\n",
      "frame: 1001\n",
      "\tboxes: 1\n",
      "frame: 1021\n",
      "\tboxes: 1\n",
      "frame: 1041\n",
      "\tboxes: 1\n",
      "frame: 1061\n",
      "\tboxes: 1\n",
      "frame: 1081\n",
      "\tboxes: 1\n",
      "frame: 1101\n",
      "\tboxes: 1\n",
      "frame: 1121\n",
      "\tboxes: 1\n",
      "frame: 1141\n",
      "\tboxes: 1\n",
      "frame: 1161\n",
      "\tboxes: 1\n",
      "frame: 1181\n",
      "\tboxes: 1\n",
      "frame: 1201\n",
      "\tboxes: 1\n",
      "frame: 1221\n",
      "\tboxes: 1\n",
      "frame: 1241\n",
      "\tboxes: 1\n",
      "frame: 1261\n",
      "\tboxes: 1\n",
      "frame: 1281\n",
      "\tboxes: 1\n",
      "frame: 1301\n",
      "\tboxes: 1\n",
      "frame: 1321\n",
      "\tboxes: 1\n",
      "frame: 1341\n",
      "\tboxes: 1\n",
      "frame: 1361\n",
      "\tboxes: 1\n",
      "frame: 1381\n",
      "\tboxes: 1\n",
      "frame: 1401\n",
      "\tboxes: 1\n",
      "frame: 1421\n",
      "\tboxes: 1\n",
      "frame: 1441\n",
      "\tboxes: 1\n",
      "frame: 1461\n",
      "\tboxes: 1\n",
      "frame: 1481\n",
      "\tboxes: 1\n",
      "frame: 1501\n",
      "\tboxes: 1\n",
      "frame: 1521\n",
      "\tboxes: 1\n",
      "frame: 1541\n",
      "\tboxes: 1\n",
      "frame: 1561\n",
      "\tboxes: 1\n",
      "frame: 1581\n",
      "\tboxes: 1\n",
      "frame: 1601\n",
      "\tboxes: 1\n",
      "frame: 1621\n",
      "\tboxes: 1\n",
      "frame: 1641\n",
      "\tboxes: 1\n",
      "frame: 1661\n",
      "frame: 1681\n",
      "\tboxes: 1\n",
      "frame: 1701\n",
      "\tboxes: 1\n",
      "frame: 1721\n",
      "\tboxes: 1\n",
      "frame: 1741\n",
      "\tboxes: 1\n",
      "frame: 1761\n",
      "frame: 1781\n",
      "frame: 1801\n",
      "frame: 1821\n",
      "frame: 1841\n",
      "frame: 1861\n",
      "frame: 1881\n",
      "frame: 1901\n",
      "\tboxes: 1\n",
      "frame: 1921\n",
      "\tboxes: 1\n",
      "frame: 1941\n",
      "\tboxes: 1\n",
      "frame: 1961\n",
      "\tboxes: 1\n",
      "frame: 1981\n",
      "\tboxes: 1\n",
      "frame: 2001\n",
      "\tboxes: 1\n",
      "frame: 2021\n",
      "frame: 2041\n",
      "frame: 2061\n",
      "frame: 2081\n",
      "\tboxes: 1\n",
      "frame: 2101\n",
      "\tboxes: 1\n",
      "frame: 2121\n",
      "\tboxes: 1\n",
      "frame: 2141\n",
      "\tboxes: 2\n",
      "frame: 2161\n",
      "\tboxes: 3\n",
      "frame: 2181\n",
      "\tboxes: 3\n",
      "frame: 2201\n",
      "\tboxes: 3\n",
      "frame: 2221\n",
      "\tboxes: 3\n",
      "frame: 2241\n",
      "\tboxes: 4\n",
      "frame: 2261\n",
      "\tboxes: 3\n",
      "frame: 2281\n",
      "\tboxes: 3\n",
      "frame: 2301\n",
      "\tboxes: 4\n",
      "frame: 2321\n",
      "\tboxes: 4\n",
      "frame: 2341\n",
      "\tboxes: 3\n",
      "frame: 2361\n",
      "\tboxes: 3\n",
      "frame: 2381\n",
      "\tboxes: 3\n",
      "frame: 2401\n",
      "\tboxes: 3\n",
      "frame: 2421\n",
      "\tboxes: 2\n",
      "frame: 2441\n",
      "\tboxes: 2\n",
      "frame: 2461\n",
      "\tboxes: 3\n",
      "frame: 2481\n",
      "\tboxes: 3\n",
      "frame: 2501\n",
      "\tboxes: 3\n",
      "frame: 2521\n",
      "\tboxes: 3\n",
      "frame: 2541\n",
      "\tboxes: 3\n",
      "frame: 2561\n",
      "\tboxes: 2\n",
      "frame: 2581\n",
      "\tboxes: 3\n",
      "frame: 2601\n",
      "\tboxes: 3\n",
      "frame: 2621\n",
      "\tboxes: 2\n",
      "frame: 2641\n",
      "\tboxes: 2\n",
      "frame: 2661\n",
      "\tboxes: 3\n",
      "frame: 2681\n",
      "\tboxes: 3\n",
      "frame: 2701\n",
      "\tboxes: 3\n",
      "frame: 2721\n",
      "\tboxes: 2\n",
      "frame: 2741\n",
      "\tboxes: 2\n",
      "frame: 2761\n",
      "\tboxes: 2\n",
      "frame: 2781\n",
      "\tboxes: 2\n",
      "frame: 2801\n",
      "\tboxes: 2\n",
      "frame: 2821\n",
      "\tboxes: 3\n",
      "frame: 2841\n",
      "\tboxes: 3\n",
      "frame: 2861\n",
      "\tboxes: 2\n",
      "frame: 2881\n",
      "\tboxes: 3\n",
      "frame: 2901\n",
      "\tboxes: 2\n",
      "frame: 2921\n",
      "\tboxes: 2\n",
      "frame: 2941\n",
      "\tboxes: 2\n",
      "frame: 2961\n",
      "\tboxes: 3\n",
      "frame: 2981\n",
      "\tboxes: 3\n",
      "frame: 3001\n",
      "\tboxes: 4\n",
      "frame: 3021\n",
      "\tboxes: 4\n",
      "frame: 3041\n",
      "\tboxes: 4\n",
      "frame: 3061\n",
      "\tboxes: 4\n",
      "frame: 3081\n",
      "\tboxes: 4\n",
      "frame: 3101\n",
      "\tboxes: 6\n",
      "frame: 3121\n",
      "\tboxes: 6\n",
      "frame: 3141\n",
      "\tboxes: 6\n",
      "frame: 3161\n",
      "\tboxes: 6\n",
      "frame: 3181\n",
      "\tboxes: 5\n",
      "frame: 3201\n",
      "\tboxes: 4\n",
      "frame: 3221\n",
      "\tboxes: 4\n",
      "frame: 3241\n",
      "\tboxes: 5\n",
      "frame: 3261\n",
      "\tboxes: 4\n",
      "frame: 3281\n",
      "\tboxes: 6\n",
      "frame: 3301\n",
      "\tboxes: 6\n",
      "frame: 3321\n",
      "\tboxes: 5\n",
      "frame: 3341\n",
      "\tboxes: 7\n",
      "frame: 3361\n",
      "\tboxes: 6\n",
      "frame: 3381\n",
      "\tboxes: 6\n",
      "frame: 3401\n",
      "\tboxes: 7\n",
      "frame: 3421\n",
      "\tboxes: 7\n",
      "frame: 3441\n",
      "\tboxes: 7\n",
      "frame: 3461\n",
      "\tboxes: 7\n",
      "frame: 3481\n",
      "\tboxes: 7\n",
      "frame: 3501\n",
      "\tboxes: 6\n",
      "frame: 3521\n",
      "\tboxes: 5\n",
      "frame: 3541\n",
      "\tboxes: 6\n",
      "frame: 3561\n",
      "\tboxes: 6\n",
      "frame: 3581\n",
      "\tboxes: 5\n",
      "frame: 3601\n",
      "\tboxes: 6\n",
      "frame: 3621\n",
      "\tboxes: 5\n",
      "frame: 3641\n",
      "\tboxes: 5\n",
      "frame: 3661\n",
      "\tboxes: 5\n",
      "frame: 3681\n",
      "\tboxes: 5\n",
      "frame: 3701\n",
      "\tboxes: 6\n",
      "frame: 3721\n",
      "\tboxes: 5\n",
      "frame: 3741\n",
      "\tboxes: 5\n",
      "frame: 3761\n",
      "\tboxes: 6\n",
      "frame: 3781\n",
      "\tboxes: 6\n",
      "frame: 3801\n",
      "\tboxes: 6\n",
      "frame: 3821\n",
      "\tboxes: 6\n",
      "frame: 3841\n",
      "\tboxes: 7\n",
      "frame: 3861\n",
      "\tboxes: 6\n",
      "frame: 3881\n",
      "\tboxes: 7\n",
      "frame: 3901\n",
      "\tboxes: 7\n",
      "frame: 3921\n",
      "\tboxes: 7\n",
      "frame: 3941\n",
      "\tboxes: 4\n",
      "frame: 3961\n",
      "\tboxes: 4\n",
      "frame: 3981\n",
      "\tboxes: 5\n",
      "frame: 4001\n",
      "\tboxes: 7\n",
      "frame: 4021\n",
      "\tboxes: 6\n",
      "frame: 4041\n",
      "\tboxes: 6\n",
      "frame: 4061\n",
      "\tboxes: 6\n",
      "frame: 4081\n",
      "\tboxes: 5\n",
      "frame: 4101\n",
      "\tboxes: 6\n",
      "frame: 4121\n",
      "\tboxes: 6\n",
      "frame: 4141\n",
      "\tboxes: 6\n",
      "frame: 4161\n",
      "\tboxes: 5\n",
      "frame: 4181\n",
      "\tboxes: 5\n",
      "frame: 4201\n",
      "\tboxes: 5\n",
      "frame: 4221\n",
      "\tboxes: 4\n",
      "frame: 4241\n",
      "\tboxes: 4\n",
      "frame: 4261\n",
      "\tboxes: 4\n",
      "frame: 4281\n",
      "\tboxes: 4\n",
      "frame: 4301\n",
      "\tboxes: 5\n",
      "frame: 4321\n",
      "\tboxes: 5\n",
      "frame: 4341\n",
      "\tboxes: 6\n",
      "frame: 4361\n",
      "\tboxes: 7\n",
      "frame: 4381\n",
      "\tboxes: 7\n",
      "frame: 4401\n",
      "\tboxes: 7\n",
      "frame: 4421\n",
      "\tboxes: 6\n",
      "frame: 4441\n",
      "\tboxes: 7\n",
      "frame: 4461\n",
      "\tboxes: 7\n",
      "frame: 4481\n",
      "\tboxes: 7\n",
      "frame: 4501\n",
      "\tboxes: 6\n",
      "frame: 4521\n",
      "\tboxes: 6\n",
      "frame: 4541\n",
      "frame: 4561\n",
      "frame: 4581\n",
      "frame: 4601\n",
      "\tboxes: 6\n",
      "frame: 4621\n",
      "\tboxes: 5\n",
      "frame: 4641\n",
      "\tboxes: 6\n",
      "frame: 4661\n",
      "\tboxes: 6\n",
      "frame: 4681\n",
      "\tboxes: 8\n",
      "frame: 4701\n",
      "\tboxes: 7\n",
      "frame: 4721\n",
      "\tboxes: 7\n",
      "frame: 4741\n",
      "\tboxes: 7\n",
      "frame: 4761\n",
      "\tboxes: 6\n",
      "frame: 4781\n",
      "\tboxes: 7\n",
      "frame: 4801\n",
      "\tboxes: 6\n",
      "frame: 4821\n",
      "\tboxes: 6\n",
      "frame: 4841\n",
      "\tboxes: 6\n",
      "frame: 4861\n",
      "\tboxes: 5\n",
      "frame: 4881\n",
      "\tboxes: 6\n",
      "frame: 4901\n",
      "\tboxes: 5\n",
      "frame: 4921\n",
      "\tboxes: 5\n",
      "frame: 4941\n",
      "\tboxes: 6\n",
      "frame: 4961\n",
      "\tboxes: 5\n",
      "frame: 4981\n",
      "\tboxes: 5\n",
      "frame: 5001\n",
      "\tboxes: 5\n",
      "frame: 5021\n",
      "\tboxes: 6\n",
      "frame: 5041\n",
      "\tboxes: 5\n",
      "frame: 5061\n",
      "\tboxes: 5\n",
      "frame: 5081\n",
      "\tboxes: 6\n",
      "frame: 5101\n",
      "\tboxes: 7\n",
      "frame: 5121\n",
      "\tboxes: 5\n",
      "frame: 5141\n",
      "\tboxes: 5\n",
      "frame: 5161\n",
      "\tboxes: 5\n",
      "frame: 5181\n",
      "frame: 5201\n",
      "\tboxes: 5\n",
      "frame: 5221\n",
      "\tboxes: 5\n",
      "frame: 5241\n",
      "\tboxes: 4\n",
      "frame: 5261\n",
      "\tboxes: 4\n",
      "frame: 5281\n",
      "\tboxes: 5\n",
      "frame: 5301\n",
      "\tboxes: 4\n",
      "frame: 5321\n",
      "\tboxes: 4\n",
      "frame: 5341\n",
      "\tboxes: 4\n",
      "frame: 5361\n",
      "\tboxes: 6\n",
      "frame: 5381\n",
      "\tboxes: 4\n",
      "frame: 5401\n",
      "\tboxes: 4\n",
      "frame: 5421\n",
      "\tboxes: 4\n",
      "frame: 5441\n",
      "\tboxes: 4\n",
      "frame: 5461\n",
      "\tboxes: 4\n",
      "frame: 5481\n",
      "\tboxes: 4\n",
      "frame: 5501\n",
      "\tboxes: 4\n",
      "frame: 5521\n",
      "\tboxes: 4\n",
      "frame: 5541\n",
      "\tboxes: 5\n",
      "frame: 5561\n",
      "\tboxes: 4\n",
      "frame: 5581\n",
      "\tboxes: 5\n",
      "frame: 5601\n",
      "\tboxes: 5\n",
      "frame: 5621\n",
      "\tboxes: 4\n",
      "frame: 5641\n",
      "\tboxes: 4\n",
      "frame: 5661\n",
      "\tboxes: 5\n",
      "frame: 5681\n",
      "\tboxes: 5\n",
      "frame: 5701\n",
      "\tboxes: 5\n",
      "frame: 5721\n",
      "\tboxes: 6\n",
      "frame: 5741\n",
      "\tboxes: 5\n",
      "frame: 5761\n",
      "\tboxes: 5\n",
      "frame: 5781\n",
      "\tboxes: 5\n",
      "frame: 5801\n",
      "\tboxes: 5\n",
      "frame: 5821\n",
      "\tboxes: 5\n",
      "frame: 5841\n",
      "\tboxes: 5\n",
      "frame: 5861\n",
      "\tboxes: 6\n",
      "frame: 5881\n",
      "\tboxes: 8\n",
      "frame: 5901\n",
      "\tboxes: 6\n",
      "frame: 5921\n",
      "\tboxes: 7\n",
      "frame: 5941\n",
      "\tboxes: 6\n",
      "frame: 5961\n",
      "\tboxes: 6\n",
      "frame: 5981\n",
      "\tboxes: 8\n",
      "frame: 6001\n",
      "\tboxes: 8\n",
      "frame: 6021\n",
      "\tboxes: 8\n",
      "frame: 6041\n",
      "\tboxes: 5\n",
      "frame: 6061\n",
      "\tboxes: 6\n",
      "frame: 6081\n",
      "\tboxes: 5\n",
      "frame: 6101\n",
      "\tboxes: 4\n",
      "frame: 6121\n",
      "\tboxes: 4\n",
      "frame: 6141\n",
      "\tboxes: 4\n",
      "frame: 6161\n",
      "\tboxes: 4\n",
      "frame: 6181\n",
      "\tboxes: 5\n",
      "frame: 6201\n",
      "\tboxes: 7\n",
      "frame: 6221\n",
      "\tboxes: 5\n",
      "frame: 6241\n",
      "\tboxes: 5\n",
      "frame: 6261\n",
      "\tboxes: 5\n",
      "frame: 6281\n",
      "\tboxes: 5\n",
      "frame: 6301\n",
      "\tboxes: 5\n",
      "frame: 6321\n",
      "\tboxes: 5\n",
      "frame: 6341\n",
      "\tboxes: 5\n",
      "frame: 6361\n",
      "\tboxes: 5\n",
      "frame: 6381\n",
      "\tboxes: 5\n",
      "frame: 6401\n",
      "\tboxes: 4\n",
      "frame: 6421\n",
      "\tboxes: 5\n",
      "frame: 6441\n",
      "\tboxes: 4\n",
      "frame: 6461\n",
      "\tboxes: 5\n",
      "frame: 6481\n",
      "\tboxes: 5\n",
      "frame: 6501\n",
      "\tboxes: 5\n",
      "frame: 6521\n",
      "\tboxes: 5\n",
      "frame: 6541\n",
      "\tboxes: 5\n",
      "frame: 6561\n",
      "\tboxes: 5\n",
      "frame: 6581\n",
      "\tboxes: 4\n",
      "frame: 6601\n",
      "\tboxes: 4\n",
      "frame: 6621\n",
      "\tboxes: 4\n",
      "frame: 6641\n",
      "\tboxes: 4\n",
      "frame: 6661\n",
      "\tboxes: 4\n",
      "frame: 6681\n",
      "\tboxes: 4\n",
      "frame: 6701\n",
      "\tboxes: 4\n",
      "frame: 6721\n",
      "\tboxes: 5\n",
      "frame: 6741\n",
      "\tboxes: 5\n",
      "frame: 6761\n",
      "\tboxes: 5\n",
      "frame: 6781\n",
      "\tboxes: 4\n",
      "frame: 6801\n",
      "\tboxes: 4\n",
      "frame: 6821\n",
      "\tboxes: 5\n",
      "frame: 6841\n",
      "\tboxes: 5\n",
      "frame: 6861\n",
      "\tboxes: 4\n",
      "frame: 6881\n",
      "\tboxes: 4\n",
      "frame: 6901\n",
      "\tboxes: 4\n",
      "frame: 6921\n",
      "\tboxes: 4\n",
      "frame: 6941\n",
      "\tboxes: 4\n",
      "frame: 6961\n",
      "\tboxes: 4\n",
      "frame: 6981\n",
      "\tboxes: 4\n",
      "frame: 7001\n",
      "\tboxes: 4\n",
      "frame: 7021\n",
      "\tboxes: 4\n",
      "frame: 7041\n",
      "\tboxes: 4\n",
      "frame: 7061\n",
      "\tboxes: 4\n",
      "frame: 7081\n",
      "\tboxes: 4\n",
      "frame: 7101\n",
      "\tboxes: 4\n",
      "frame: 7121\n",
      "\tboxes: 4\n",
      "frame: 7141\n",
      "\tboxes: 4\n",
      "frame: 7161\n",
      "\tboxes: 4\n",
      "frame: 7181\n",
      "\tboxes: 4\n",
      "frame: 7201\n",
      "\tboxes: 4\n",
      "frame: 7221\n",
      "\tboxes: 4\n",
      "frame: 7241\n",
      "\tboxes: 4\n",
      "frame: 7261\n",
      "\tboxes: 4\n",
      "frame: 7281\n",
      "\tboxes: 4\n",
      "frame: 7301\n",
      "\tboxes: 4\n",
      "frame: 7321\n",
      "\tboxes: 4\n",
      "frame: 7341\n",
      "\tboxes: 5\n",
      "frame: 7361\n",
      "\tboxes: 5\n",
      "frame: 7381\n",
      "\tboxes: 5\n",
      "frame: 7401\n",
      "\tboxes: 4\n",
      "frame: 7421\n",
      "\tboxes: 4\n",
      "frame: 7441\n",
      "\tboxes: 4\n",
      "frame: 7461\n",
      "\tboxes: 4\n",
      "frame: 7481\n",
      "\tboxes: 5\n",
      "frame: 7501\n",
      "\tboxes: 5\n",
      "frame: 7521\n",
      "\tboxes: 5\n",
      "frame: 7541\n",
      "\tboxes: 6\n",
      "frame: 7561\n",
      "\tboxes: 4\n",
      "frame: 7581\n",
      "\tboxes: 4\n",
      "frame: 7601\n",
      "\tboxes: 4\n",
      "frame: 7621\n",
      "\tboxes: 4\n",
      "frame: 7641\n",
      "\tboxes: 4\n",
      "frame: 7661\n",
      "\tboxes: 5\n",
      "frame: 7681\n",
      "\tboxes: 5\n",
      "frame: 7701\n",
      "\tboxes: 5\n",
      "frame: 7721\n",
      "\tboxes: 5\n",
      "frame: 7741\n",
      "\tboxes: 6\n",
      "frame: 7761\n",
      "\tboxes: 7\n",
      "frame: 7781\n",
      "\tboxes: 6\n",
      "frame: 7801\n",
      "\tboxes: 4\n",
      "frame: 7821\n",
      "\tboxes: 6\n",
      "frame: 7841\n",
      "\tboxes: 6\n",
      "frame: 7861\n",
      "\tboxes: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame: 7881\n",
      "\tboxes: 4\n",
      "frame: 7901\n",
      "\tboxes: 4\n",
      "frame: 7921\n",
      "\tboxes: 5\n",
      "frame: 7941\n",
      "\tboxes: 5\n",
      "frame: 7961\n",
      "\tboxes: 5\n",
      "frame: 7981\n",
      "frame: 8001\n",
      "frame: 8021\n",
      "frame: 8041\n",
      "\tboxes: 4\n",
      "frame: 8061\n",
      "\tboxes: 4\n",
      "frame: 8081\n",
      "\tboxes: 5\n",
      "frame: 8101\n",
      "\tboxes: 4\n",
      "frame: 8121\n",
      "\tboxes: 5\n",
      "frame: 8141\n",
      "\tboxes: 5\n",
      "frame: 8161\n",
      "\tboxes: 5\n",
      "frame: 8181\n",
      "\tboxes: 5\n",
      "frame: 8201\n",
      "\tboxes: 4\n",
      "frame: 8221\n",
      "\tboxes: 4\n",
      "frame: 8241\n",
      "\tboxes: 4\n",
      "frame: 8261\n",
      "\tboxes: 4\n",
      "frame: 8281\n",
      "\tboxes: 5\n",
      "frame: 8301\n",
      "\tboxes: 5\n",
      "frame: 8321\n",
      "\tboxes: 6\n",
      "frame: 8341\n",
      "\tboxes: 6\n",
      "frame: 8361\n",
      "\tboxes: 3\n",
      "frame: 8381\n",
      "\tboxes: 4\n",
      "frame: 8401\n",
      "\tboxes: 3\n",
      "frame: 8421\n",
      "\tboxes: 3\n",
      "frame: 8441\n",
      "\tboxes: 4\n",
      "frame: 8461\n",
      "\tboxes: 4\n",
      "frame: 8481\n",
      "\tboxes: 3\n",
      "frame: 8501\n",
      "\tboxes: 4\n",
      "frame: 8521\n",
      "\tboxes: 3\n",
      "frame: 8541\n",
      "\tboxes: 4\n",
      "frame: 8561\n",
      "\tboxes: 4\n",
      "frame: 8581\n",
      "\tboxes: 3\n",
      "frame: 8601\n",
      "\tboxes: 3\n",
      "frame: 8621\n",
      "\tboxes: 3\n",
      "frame: 8641\n",
      "\tboxes: 4\n",
      "frame: 8661\n",
      "\tboxes: 3\n",
      "frame: 8681\n",
      "\tboxes: 3\n",
      "frame: 8701\n",
      "\tboxes: 3\n",
      "frame: 8721\n",
      "\tboxes: 4\n",
      "frame: 8741\n",
      "\tboxes: 4\n",
      "frame: 8761\n",
      "\tboxes: 4\n",
      "frame: 8781\n",
      "\tboxes: 4\n",
      "frame: 8801\n",
      "\tboxes: 4\n",
      "frame: 8821\n",
      "\tboxes: 3\n",
      "frame: 8841\n",
      "\tboxes: 3\n",
      "frame: 8861\n",
      "\tboxes: 3\n",
      "frame: 8881\n",
      "\tboxes: 3\n",
      "frame: 8901\n",
      "\tboxes: 3\n",
      "frame: 8921\n",
      "\tboxes: 3\n",
      "frame: 8941\n",
      "\tboxes: 3\n",
      "frame: 8961\n",
      "\tboxes: 3\n",
      "frame: 8981\n",
      "\tboxes: 4\n",
      "frame: 9001\n",
      "\tboxes: 4\n",
      "frame: 9021\n",
      "\tboxes: 3\n",
      "frame: 9041\n",
      "\tboxes: 4\n",
      "frame: 9061\n",
      "\tboxes: 4\n",
      "frame: 9081\n",
      "\tboxes: 3\n",
      "frame: 9101\n",
      "\tboxes: 3\n",
      "frame: 9121\n",
      "\tboxes: 3\n",
      "frame: 9141\n",
      "\tboxes: 3\n",
      "frame: 9161\n",
      "\tboxes: 3\n",
      "frame: 9181\n",
      "\tboxes: 4\n",
      "frame: 9201\n",
      "\tboxes: 3\n",
      "frame: 9221\n",
      "\tboxes: 3\n",
      "frame: 9241\n",
      "\tboxes: 5\n",
      "frame: 9261\n",
      "\tboxes: 4\n",
      "frame: 9281\n",
      "\tboxes: 4\n",
      "frame: 9301\n",
      "\tboxes: 4\n",
      "frame: 9321\n",
      "\tboxes: 3\n",
      "frame: 9341\n",
      "\tboxes: 3\n",
      "frame: 9361\n",
      "\tboxes: 3\n",
      "frame: 9381\n",
      "\tboxes: 4\n",
      "frame: 9401\n",
      "\tboxes: 4\n",
      "frame: 9421\n",
      "\tboxes: 3\n",
      "frame: 9441\n",
      "\tboxes: 4\n",
      "frame: 9461\n",
      "\tboxes: 4\n",
      "frame: 9481\n",
      "\tboxes: 3\n",
      "frame: 9501\n",
      "\tboxes: 3\n",
      "frame: 9521\n",
      "\tboxes: 4\n",
      "frame: 9541\n",
      "\tboxes: 3\n",
      "frame: 9561\n",
      "\tboxes: 3\n",
      "frame: 9581\n",
      "\tboxes: 3\n",
      "frame: 9601\n",
      "\tboxes: 4\n",
      "frame: 9621\n",
      "\tboxes: 4\n",
      "frame: 9641\n",
      "\tboxes: 3\n",
      "frame: 9661\n",
      "\tboxes: 4\n",
      "frame: 9681\n",
      "\tboxes: 6\n",
      "frame: 9701\n",
      "\tboxes: 6\n",
      "frame: 9721\n",
      "\tboxes: 6\n",
      "frame: 9741\n",
      "\tboxes: 6\n",
      "frame: 9761\n",
      "\tboxes: 3\n",
      "frame: 9781\n",
      "\tboxes: 4\n",
      "frame: 9801\n",
      "\tboxes: 5\n",
      "frame: 9821\n",
      "\tboxes: 5\n",
      "frame: 9841\n",
      "\tboxes: 5\n",
      "frame: 9861\n",
      "\tboxes: 5\n",
      "frame: 9881\n",
      "\tboxes: 5\n",
      "frame: 9901\n",
      "\tboxes: 5\n",
      "frame: 9921\n",
      "\tboxes: 5\n",
      "frame: 9941\n",
      "\tboxes: 5\n",
      "frame: 9961\n",
      "\tboxes: 5\n",
      "frame: 9981\n",
      "\tboxes: 3\n",
      "frame: 10001\n",
      "\tboxes: 5\n",
      "frame: 10021\n",
      "\tboxes: 4\n",
      "frame: 10041\n",
      "\tboxes: 4\n",
      "frame: 10061\n",
      "\tboxes: 4\n",
      "frame: 10081\n",
      "\tboxes: 4\n",
      "frame: 10101\n",
      "\tboxes: 4\n",
      "frame: 10121\n",
      "\tboxes: 4\n",
      "frame: 10141\n",
      "\tboxes: 4\n",
      "frame: 10161\n",
      "\tboxes: 4\n",
      "frame: 10181\n",
      "\tboxes: 4\n",
      "frame: 10201\n",
      "\tboxes: 4\n",
      "frame: 10221\n",
      "\tboxes: 3\n",
      "frame: 10241\n",
      "\tboxes: 4\n",
      "frame: 10261\n",
      "\tboxes: 4\n",
      "frame: 10281\n",
      "\tboxes: 4\n",
      "frame: 10301\n",
      "\tboxes: 3\n",
      "frame: 10321\n",
      "\tboxes: 3\n",
      "frame: 10341\n",
      "\tboxes: 3\n",
      "frame: 10361\n",
      "\tboxes: 4\n",
      "frame: 10381\n",
      "\tboxes: 4\n",
      "frame: 10401\n",
      "\tboxes: 4\n",
      "frame: 10421\n",
      "\tboxes: 5\n",
      "frame: 10441\n",
      "\tboxes: 5\n",
      "frame: 10461\n",
      "\tboxes: 5\n",
      "frame: 10481\n",
      "\tboxes: 4\n",
      "frame: 10501\n",
      "\tboxes: 5\n",
      "frame: 10521\n",
      "\tboxes: 5\n",
      "frame: 10541\n",
      "\tboxes: 5\n",
      "frame: 10561\n",
      "\tboxes: 5\n",
      "frame: 10581\n",
      "\tboxes: 5\n",
      "frame: 10601\n",
      "\tboxes: 4\n",
      "frame: 10621\n",
      "\tboxes: 5\n",
      "frame: 10641\n",
      "\tboxes: 4\n",
      "frame: 10661\n",
      "\tboxes: 5\n",
      "frame: 10681\n",
      "\tboxes: 5\n",
      "frame: 10701\n",
      "\tboxes: 4\n",
      "frame: 10721\n",
      "\tboxes: 4\n",
      "frame: 10741\n",
      "\tboxes: 4\n",
      "frame: 10761\n",
      "\tboxes: 5\n",
      "frame: 10781\n",
      "\tboxes: 5\n",
      "frame: 10801\n",
      "\tboxes: 5\n",
      "frame: 10821\n",
      "\tboxes: 4\n",
      "frame: 10841\n",
      "\tboxes: 4\n",
      "frame: 10861\n",
      "\tboxes: 4\n",
      "frame: 10881\n",
      "\tboxes: 4\n",
      "frame: 10901\n",
      "\tboxes: 5\n",
      "frame: 10921\n",
      "\tboxes: 4\n",
      "frame: 10941\n",
      "frame: 10961\n",
      "frame: 10981\n",
      "frame: 11001\n",
      "\tboxes: 4\n",
      "frame: 11021\n",
      "\tboxes: 4\n",
      "frame: 11041\n",
      "\tboxes: 5\n",
      "frame: 11061\n",
      "\tboxes: 5\n",
      "frame: 11081\n",
      "\tboxes: 5\n",
      "frame: 11101\n",
      "\tboxes: 5\n",
      "frame: 11121\n",
      "\tboxes: 4\n",
      "frame: 11141\n",
      "\tboxes: 5\n",
      "frame: 11161\n",
      "\tboxes: 4\n",
      "frame: 11181\n",
      "\tboxes: 3\n",
      "frame: 11201\n",
      "\tboxes: 3\n",
      "frame: 11221\n",
      "\tboxes: 3\n",
      "frame: 11241\n",
      "\tboxes: 7\n",
      "frame: 11261\n",
      "\tboxes: 6\n",
      "frame: 11281\n",
      "\tboxes: 6\n",
      "frame: 11301\n",
      "\tboxes: 6\n",
      "frame: 11321\n",
      "\tboxes: 6\n",
      "frame: 11341\n",
      "\tboxes: 5\n",
      "frame: 11361\n",
      "\tboxes: 6\n",
      "frame: 11381\n",
      "\tboxes: 6\n",
      "frame: 11401\n",
      "\tboxes: 6\n",
      "frame: 11421\n",
      "\tboxes: 6\n",
      "frame: 11441\n",
      "\tboxes: 6\n",
      "frame: 11461\n",
      "\tboxes: 5\n",
      "frame: 11481\n",
      "\tboxes: 5\n",
      "frame: 11501\n",
      "\tboxes: 6\n",
      "frame: 11521\n",
      "\tboxes: 6\n",
      "frame: 11541\n",
      "\tboxes: 6\n",
      "frame: 11561\n",
      "\tboxes: 7\n",
      "frame: 11581\n",
      "\tboxes: 7\n",
      "frame: 11601\n",
      "\tboxes: 6\n",
      "frame: 11621\n",
      "\tboxes: 6\n",
      "frame: 11641\n",
      "\tboxes: 6\n",
      "frame: 11661\n",
      "\tboxes: 6\n",
      "frame: 11681\n",
      "\tboxes: 6\n",
      "frame: 11701\n",
      "\tboxes: 6\n",
      "frame: 11721\n",
      "\tboxes: 7\n",
      "frame: 11741\n",
      "\tboxes: 7\n",
      "frame: 11761\n",
      "\tboxes: 7\n",
      "frame: 11781\n",
      "\tboxes: 6\n",
      "frame: 11801\n",
      "\tboxes: 6\n",
      "frame: 11821\n",
      "\tboxes: 6\n",
      "frame: 11841\n",
      "\tboxes: 6\n",
      "frame: 11861\n",
      "\tboxes: 6\n",
      "frame: 11881\n",
      "\tboxes: 7\n",
      "frame: 11901\n",
      "\tboxes: 6\n",
      "frame: 11921\n",
      "\tboxes: 6\n",
      "frame: 11941\n",
      "\tboxes: 6\n",
      "frame: 11961\n",
      "\tboxes: 7\n",
      "frame: 11981\n",
      "\tboxes: 6\n",
      "frame: 12001\n",
      "\tboxes: 7\n",
      "frame: 12021\n",
      "\tboxes: 6\n",
      "frame: 12041\n",
      "\tboxes: 6\n",
      "frame: 12061\n",
      "\tboxes: 6\n",
      "frame: 12081\n",
      "\tboxes: 5\n",
      "frame: 12101\n",
      "\tboxes: 7\n",
      "frame: 12121\n",
      "\tboxes: 7\n",
      "frame: 12141\n",
      "\tboxes: 6\n",
      "frame: 12161\n",
      "\tboxes: 6\n",
      "frame: 12181\n",
      "\tboxes: 6\n",
      "frame: 12201\n",
      "\tboxes: 8\n",
      "frame: 12221\n",
      "\tboxes: 8\n",
      "frame: 12241\n",
      "\tboxes: 7\n",
      "frame: 12261\n",
      "\tboxes: 7\n",
      "frame: 12281\n",
      "\tboxes: 10\n",
      "frame: 12301\n",
      "\tboxes: 10\n",
      "frame: 12321\n",
      "\tboxes: 8\n",
      "frame: 12341\n",
      "\tboxes: 8\n",
      "frame: 12361\n",
      "\tboxes: 7\n",
      "frame: 12381\n",
      "\tboxes: 6\n",
      "frame: 12401\n",
      "\tboxes: 7\n",
      "frame: 12421\n",
      "frame: 12441\n",
      "\tboxes: 5\n",
      "frame: 12461\n",
      "\tboxes: 5\n",
      "frame: 12481\n",
      "\tboxes: 6\n",
      "frame: 12501\n",
      "\tboxes: 6\n",
      "frame: 12521\n",
      "\tboxes: 7\n",
      "frame: 12541\n",
      "\tboxes: 6\n",
      "frame: 12561\n",
      "\tboxes: 7\n",
      "frame: 12581\n",
      "\tboxes: 6\n",
      "frame: 12601\n",
      "\tboxes: 6\n",
      "frame: 12621\n",
      "\tboxes: 7\n",
      "frame: 12641\n",
      "\tboxes: 7\n",
      "frame: 12661\n",
      "\tboxes: 8\n",
      "frame: 12681\n",
      "\tboxes: 7\n",
      "frame: 12701\n",
      "\tboxes: 8\n",
      "frame: 12721\n",
      "\tboxes: 5\n",
      "frame: 12741\n",
      "\tboxes: 6\n",
      "frame: 12761\n",
      "\tboxes: 6\n",
      "frame: 12781\n",
      "\tboxes: 6\n",
      "frame: 12801\n",
      "\tboxes: 7\n",
      "frame: 12821\n",
      "\tboxes: 7\n",
      "frame: 12841\n",
      "\tboxes: 6\n",
      "frame: 12861\n",
      "\tboxes: 5\n",
      "frame: 12881\n",
      "\tboxes: 5\n",
      "frame: 12901\n",
      "\tboxes: 5\n",
      "frame: 12921\n",
      "\tboxes: 5\n",
      "frame: 12941\n",
      "\tboxes: 6\n",
      "frame: 12961\n",
      "\tboxes: 6\n",
      "frame: 12981\n",
      "\tboxes: 6\n",
      "frame: 13001\n",
      "\tboxes: 6\n",
      "frame: 13021\n",
      "\tboxes: 7\n",
      "frame: 13041\n",
      "\tboxes: 8\n",
      "frame: 13061\n",
      "\tboxes: 7\n",
      "frame: 13081\n",
      "\tboxes: 8\n",
      "frame: 13101\n",
      "\tboxes: 8\n",
      "frame: 13121\n",
      "\tboxes: 7\n",
      "frame: 13141\n",
      "\tboxes: 7\n",
      "frame: 13161\n",
      "\tboxes: 7\n",
      "frame: 13181\n",
      "\tboxes: 7\n",
      "frame: 13201\n",
      "\tboxes: 7\n",
      "frame: 13221\n",
      "\tboxes: 7\n",
      "frame: 13241\n",
      "\tboxes: 6\n",
      "frame: 13261\n",
      "\tboxes: 6\n",
      "frame: 13281\n",
      "\tboxes: 6\n",
      "frame: 13301\n",
      "\tboxes: 5\n",
      "frame: 13321\n",
      "\tboxes: 6\n",
      "frame: 13341\n",
      "\tboxes: 6\n",
      "frame: 13361\n",
      "\tboxes: 6\n",
      "frame: 13381\n",
      "\tboxes: 7\n",
      "frame: 13401\n",
      "\tboxes: 7\n",
      "frame: 13421\n",
      "\tboxes: 7\n",
      "frame: 13441\n",
      "\tboxes: 6\n",
      "frame: 13461\n",
      "\tboxes: 6\n",
      "frame: 13481\n",
      "\tboxes: 7\n",
      "frame: 13501\n",
      "\tboxes: 7\n",
      "frame: 13521\n",
      "\tboxes: 6\n",
      "frame: 13541\n",
      "\tboxes: 7\n",
      "frame: 13561\n",
      "\tboxes: 6\n",
      "frame: 13581\n",
      "\tboxes: 6\n",
      "frame: 13601\n",
      "\tboxes: 6\n",
      "frame: 13621\n",
      "\tboxes: 6\n",
      "frame: 13641\n",
      "\tboxes: 6\n",
      "frame: 13661\n",
      "\tboxes: 7\n",
      "frame: 13681\n",
      "\tboxes: 7\n",
      "frame: 13701\n",
      "\tboxes: 7\n",
      "frame: 13721\n",
      "\tboxes: 6\n",
      "frame: 13741\n",
      "\tboxes: 5\n",
      "frame: 13761\n",
      "\tboxes: 5\n",
      "frame: 13781\n",
      "\tboxes: 5\n",
      "frame: 13801\n",
      "\tboxes: 5\n",
      "frame: 13821\n",
      "\tboxes: 6\n",
      "frame: 13841\n",
      "\tboxes: 6\n",
      "frame: 13861\n",
      "\tboxes: 6\n",
      "frame: 13881\n",
      "\tboxes: 7\n",
      "frame: 13901\n",
      "\tboxes: 6\n",
      "frame: 13921\n",
      "\tboxes: 5\n",
      "frame: 13941\n",
      "\tboxes: 6\n",
      "frame: 13961\n",
      "\tboxes: 7\n",
      "frame: 13981\n",
      "\tboxes: 8\n",
      "frame: 14001\n",
      "\tboxes: 7\n",
      "frame: 14021\n",
      "\tboxes: 7\n",
      "frame: 14041\n",
      "\tboxes: 7\n",
      "frame: 14061\n",
      "\tboxes: 6\n",
      "frame: 14081\n",
      "\tboxes: 6\n",
      "frame: 14101\n",
      "\tboxes: 6\n",
      "frame: 14121\n",
      "\tboxes: 7\n",
      "frame: 14141\n",
      "\tboxes: 7\n",
      "frame: 14161\n",
      "\tboxes: 7\n",
      "frame: 14181\n",
      "\tboxes: 5\n",
      "frame: 14201\n",
      "\tboxes: 5\n",
      "frame: 14221\n",
      "\tboxes: 7\n",
      "frame: 14241\n",
      "\tboxes: 7\n",
      "frame: 14261\n",
      "\tboxes: 7\n",
      "frame: 14281\n",
      "\tboxes: 7\n",
      "frame: 14301\n",
      "\tboxes: 7\n",
      "frame: 14321\n",
      "\tboxes: 7\n",
      "frame: 14341\n",
      "\tboxes: 6\n",
      "frame: 14361\n",
      "\tboxes: 7\n",
      "frame: 14381\n",
      "\tboxes: 5\n",
      "frame: 14401\n",
      "\tboxes: 8\n",
      "frame: 14421\n",
      "\tboxes: 7\n",
      "frame: 14441\n",
      "\tboxes: 7\n",
      "frame: 14461\n",
      "\tboxes: 7\n",
      "frame: 14481\n",
      "\tboxes: 6\n",
      "frame: 14501\n",
      "\tboxes: 8\n",
      "frame: 14521\n",
      "\tboxes: 6\n",
      "frame: 14541\n",
      "\tboxes: 7\n",
      "frame: 14561\n",
      "\tboxes: 6\n",
      "frame: 14581\n",
      "\tboxes: 6\n",
      "frame: 14601\n",
      "\tboxes: 6\n",
      "frame: 14621\n",
      "\tboxes: 7\n",
      "frame: 14641\n",
      "\tboxes: 6\n",
      "frame: 14661\n",
      "\tboxes: 5\n",
      "frame: 14681\n",
      "\tboxes: 5\n",
      "frame: 14701\n",
      "\tboxes: 5\n",
      "frame: 14721\n",
      "\tboxes: 5\n",
      "frame: 14741\n",
      "\tboxes: 5\n",
      "frame: 14761\n",
      "\tboxes: 5\n",
      "frame: 14781\n",
      "\tboxes: 5\n",
      "frame: 14801\n",
      "\tboxes: 5\n",
      "frame: 14821\n",
      "\tboxes: 5\n",
      "frame: 14841\n",
      "\tboxes: 5\n",
      "frame: 14861\n",
      "\tboxes: 7\n",
      "frame: 14881\n",
      "\tboxes: 5\n",
      "frame: 14901\n",
      "\tboxes: 6\n",
      "frame: 14921\n",
      "\tboxes: 7\n",
      "frame: 14941\n",
      "\tboxes: 7\n",
      "frame: 14961\n",
      "\tboxes: 7\n",
      "frame: 14981\n",
      "\tboxes: 7\n",
      "frame: 15001\n",
      "\tboxes: 7\n",
      "frame: 15021\n",
      "\tboxes: 8\n",
      "frame: 15041\n",
      "\tboxes: 7\n",
      "frame: 15061\n",
      "\tboxes: 6\n",
      "frame: 15081\n",
      "\tboxes: 6\n",
      "frame: 15101\n",
      "\tboxes: 7\n",
      "frame: 15121\n",
      "\tboxes: 6\n",
      "frame: 15141\n",
      "\tboxes: 7\n",
      "frame: 15161\n",
      "\tboxes: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame: 15181\n",
      "\tboxes: 6\n",
      "frame: 15201\n",
      "\tboxes: 6\n",
      "frame: 15221\n",
      "\tboxes: 6\n",
      "frame: 15241\n",
      "\tboxes: 6\n",
      "frame: 15261\n",
      "\tboxes: 5\n",
      "frame: 15281\n",
      "\tboxes: 6\n",
      "frame: 15301\n",
      "\tboxes: 5\n",
      "frame: 15321\n",
      "\tboxes: 5\n",
      "frame: 15341\n",
      "\tboxes: 6\n",
      "frame: 15361\n",
      "\tboxes: 6\n",
      "frame: 15381\n",
      "\tboxes: 7\n",
      "frame: 15401\n",
      "\tboxes: 6\n",
      "frame: 15421\n",
      "\tboxes: 6\n",
      "frame: 15441\n",
      "\tboxes: 6\n",
      "frame: 15461\n",
      "\tboxes: 7\n",
      "frame: 15481\n",
      "\tboxes: 6\n",
      "frame: 15501\n",
      "\tboxes: 7\n",
      "frame: 15521\n",
      "\tboxes: 7\n",
      "frame: 15541\n",
      "\tboxes: 6\n",
      "frame: 15561\n",
      "\tboxes: 6\n",
      "frame: 15581\n",
      "\tboxes: 5\n",
      "frame: 15601\n",
      "\tboxes: 6\n",
      "frame: 15621\n",
      "\tboxes: 6\n",
      "frame: 15641\n",
      "\tboxes: 6\n",
      "frame: 15661\n",
      "\tboxes: 6\n",
      "frame: 15681\n",
      "\tboxes: 5\n",
      "frame: 15701\n",
      "\tboxes: 6\n",
      "frame: 15721\n",
      "\tboxes: 6\n",
      "frame: 15741\n",
      "\tboxes: 6\n",
      "frame: 15761\n",
      "\tboxes: 6\n",
      "frame: 15781\n",
      "\tboxes: 6\n",
      "frame: 15801\n",
      "\tboxes: 6\n",
      "frame: 15821\n",
      "\tboxes: 5\n",
      "frame: 15841\n",
      "\tboxes: 6\n",
      "frame: 15861\n",
      "\tboxes: 5\n",
      "frame: 15881\n",
      "\tboxes: 5\n",
      "frame: 15901\n",
      "\tboxes: 5\n",
      "frame: 15921\n",
      "\tboxes: 5\n",
      "frame: 15941\n",
      "\tboxes: 5\n",
      "frame: 15961\n",
      "\tboxes: 5\n",
      "frame: 15981\n",
      "\tboxes: 5\n",
      "frame: 16001\n",
      "\tboxes: 6\n",
      "frame: 16021\n",
      "\tboxes: 7\n",
      "frame: 16041\n",
      "\tboxes: 6\n",
      "frame: 16061\n",
      "\tboxes: 6\n",
      "frame: 16081\n",
      "\tboxes: 7\n",
      "frame: 16101\n",
      "\tboxes: 7\n",
      "frame: 16121\n",
      "\tboxes: 5\n",
      "frame: 16141\n",
      "\tboxes: 6\n",
      "frame: 16161\n",
      "\tboxes: 7\n",
      "frame: 16181\n",
      "\tboxes: 6\n",
      "frame: 16201\n",
      "\tboxes: 6\n",
      "frame: 16221\n",
      "\tboxes: 6\n",
      "frame: 16241\n",
      "\tboxes: 5\n",
      "frame: 16261\n",
      "\tboxes: 5\n",
      "frame: 16281\n",
      "\tboxes: 6\n",
      "frame: 16301\n",
      "\tboxes: 6\n",
      "frame: 16321\n",
      "\tboxes: 5\n",
      "frame: 16341\n",
      "\tboxes: 6\n",
      "frame: 16361\n",
      "\tboxes: 5\n",
      "frame: 16381\n",
      "\tboxes: 5\n",
      "frame: 16401\n",
      "\tboxes: 5\n",
      "frame: 16421\n",
      "\tboxes: 6\n",
      "frame: 16441\n",
      "\tboxes: 6\n",
      "frame: 16461\n",
      "\tboxes: 6\n",
      "frame: 16481\n",
      "\tboxes: 6\n",
      "frame: 16501\n",
      "\tboxes: 5\n",
      "frame: 16521\n",
      "\tboxes: 5\n",
      "frame: 16541\n",
      "\tboxes: 5\n",
      "frame: 16561\n",
      "\tboxes: 6\n",
      "frame: 16581\n",
      "\tboxes: 6\n",
      "frame: 16601\n",
      "\tboxes: 5\n",
      "frame: 16621\n",
      "\tboxes: 6\n",
      "frame: 16641\n",
      "\tboxes: 6\n",
      "frame: 16661\n",
      "\tboxes: 7\n",
      "frame: 16681\n",
      "\tboxes: 7\n",
      "frame: 16701\n",
      "\tboxes: 7\n",
      "frame: 16721\n",
      "\tboxes: 7\n",
      "frame: 16741\n",
      "\tboxes: 6\n",
      "frame: 16761\n",
      "\tboxes: 8\n",
      "frame: 16781\n",
      "\tboxes: 8\n",
      "frame: 16801\n",
      "\tboxes: 7\n",
      "frame: 16821\n",
      "\tboxes: 7\n",
      "frame: 16841\n",
      "\tboxes: 8\n",
      "frame: 16861\n",
      "\tboxes: 8\n",
      "frame: 16881\n",
      "\tboxes: 8\n",
      "frame: 16901\n",
      "\tboxes: 7\n",
      "frame: 16921\n",
      "\tboxes: 7\n",
      "frame: 16941\n",
      "\tboxes: 8\n",
      "frame: 16961\n",
      "\tboxes: 9\n",
      "frame: 16981\n",
      "\tboxes: 8\n",
      "frame: 17001\n",
      "\tboxes: 8\n",
      "frame: 17021\n",
      "\tboxes: 8\n",
      "frame: 17041\n",
      "\tboxes: 8\n",
      "frame: 17061\n",
      "\tboxes: 8\n",
      "frame: 17081\n",
      "\tboxes: 8\n",
      "frame: 17101\n",
      "\tboxes: 8\n",
      "frame: 17121\n",
      "\tboxes: 8\n",
      "frame: 17141\n",
      "\tboxes: 8\n",
      "frame: 17161\n",
      "\tboxes: 7\n",
      "frame: 17181\n",
      "\tboxes: 7\n",
      "frame: 17201\n",
      "\tboxes: 7\n",
      "frame: 17221\n",
      "\tboxes: 7\n",
      "frame: 17241\n",
      "\tboxes: 7\n",
      "frame: 17261\n",
      "\tboxes: 8\n",
      "frame: 17281\n",
      "\tboxes: 7\n",
      "frame: 17301\n",
      "\tboxes: 7\n",
      "frame: 17321\n",
      "\tboxes: 7\n",
      "frame: 17341\n",
      "\tboxes: 7\n",
      "frame: 17361\n",
      "\tboxes: 7\n",
      "frame: 17381\n",
      "\tboxes: 7\n",
      "frame: 17401\n",
      "\tboxes: 7\n",
      "frame: 17421\n",
      "\tboxes: 8\n",
      "frame: 17441\n",
      "\tboxes: 9\n",
      "frame: 17461\n",
      "\tboxes: 9\n",
      "frame: 17481\n",
      "\tboxes: 8\n",
      "frame: 17501\n",
      "\tboxes: 9\n",
      "frame: 17521\n",
      "\tboxes: 8\n",
      "frame: 17541\n",
      "\tboxes: 9\n",
      "frame: 17561\n",
      "\tboxes: 8\n",
      "frame: 17581\n",
      "\tboxes: 9\n",
      "frame: 17601\n",
      "\tboxes: 9\n",
      "frame: 17621\n",
      "\tboxes: 9\n",
      "frame: 17641\n",
      "\tboxes: 9\n",
      "frame: 17661\n",
      "\tboxes: 9\n",
      "frame: 17681\n",
      "\tboxes: 7\n",
      "frame: 17701\n",
      "\tboxes: 7\n",
      "frame: 17721\n",
      "\tboxes: 10\n",
      "frame: 17741\n",
      "\tboxes: 8\n",
      "frame: 17761\n",
      "\tboxes: 8\n",
      "frame: 17781\n",
      "\tboxes: 8\n",
      "frame: 17801\n",
      "\tboxes: 9\n",
      "frame: 17821\n",
      "\tboxes: 9\n",
      "frame: 17841\n",
      "\tboxes: 9\n",
      "frame: 17861\n",
      "\tboxes: 9\n",
      "frame: 17881\n",
      "\tboxes: 9\n",
      "frame: 17901\n",
      "\tboxes: 8\n",
      "frame: 17921\n",
      "\tboxes: 7\n",
      "frame: 17941\n",
      "\tboxes: 8\n",
      "frame: 17961\n",
      "\tboxes: 10\n",
      "frame: 17981\n",
      "\tboxes: 7\n",
      "frame: 18001\n",
      "\tboxes: 8\n",
      "frame: 18021\n",
      "\tboxes: 7\n",
      "frame: 18041\n",
      "\tboxes: 8\n",
      "frame: 18061\n",
      "frame: 18081\n",
      "\tboxes: 8\n",
      "frame: 18101\n",
      "\tboxes: 8\n",
      "frame: 18121\n",
      "\tboxes: 7\n",
      "frame: 18141\n",
      "\tboxes: 8\n",
      "frame: 18161\n",
      "\tboxes: 7\n",
      "frame: 18181\n",
      "\tboxes: 8\n",
      "frame: 18201\n",
      "\tboxes: 8\n",
      "frame: 18221\n",
      "\tboxes: 8\n",
      "frame: 18241\n",
      "\tboxes: 9\n",
      "frame: 18261\n",
      "\tboxes: 9\n",
      "frame: 18281\n",
      "\tboxes: 9\n",
      "frame: 18301\n",
      "\tboxes: 9\n",
      "frame: 18321\n",
      "\tboxes: 9\n",
      "frame: 18341\n",
      "\tboxes: 9\n",
      "frame: 18361\n",
      "\tboxes: 9\n",
      "frame: 18381\n",
      "\tboxes: 8\n",
      "frame: 18401\n",
      "\tboxes: 9\n",
      "frame: 18421\n",
      "\tboxes: 9\n",
      "frame: 18441\n",
      "\tboxes: 8\n",
      "frame: 18461\n",
      "\tboxes: 8\n",
      "frame: 18481\n",
      "\tboxes: 8\n",
      "frame: 18501\n",
      "\tboxes: 9\n",
      "frame: 18521\n",
      "\tboxes: 8\n",
      "frame: 18541\n",
      "\tboxes: 8\n",
      "frame: 18561\n",
      "\tboxes: 8\n",
      "frame: 18581\n",
      "\tboxes: 7\n",
      "frame: 18601\n",
      "\tboxes: 8\n",
      "frame: 18621\n",
      "\tboxes: 7\n",
      "frame: 18641\n",
      "\tboxes: 7\n",
      "frame: 18661\n",
      "\tboxes: 7\n",
      "frame: 18681\n",
      "\tboxes: 7\n",
      "frame: 18701\n",
      "\tboxes: 8\n",
      "frame: 18721\n",
      "\tboxes: 7\n",
      "frame: 18741\n",
      "\tboxes: 7\n",
      "frame: 18761\n",
      "\tboxes: 7\n",
      "frame: 18781\n",
      "\tboxes: 7\n",
      "frame: 18801\n",
      "\tboxes: 8\n",
      "frame: 18821\n",
      "\tboxes: 8\n",
      "frame: 18841\n",
      "\tboxes: 8\n",
      "frame: 18861\n",
      "\tboxes: 8\n",
      "frame: 18881\n",
      "\tboxes: 8\n",
      "frame: 18901\n",
      "\tboxes: 8\n",
      "frame: 18921\n",
      "\tboxes: 7\n",
      "frame: 18941\n",
      "\tboxes: 7\n",
      "frame: 18961\n",
      "\tboxes: 7\n",
      "frame: 18981\n",
      "\tboxes: 7\n",
      "frame: 19001\n",
      "\tboxes: 7\n",
      "frame: 19021\n",
      "\tboxes: 7\n",
      "frame: 19041\n",
      "\tboxes: 7\n",
      "frame: 19061\n",
      "\tboxes: 7\n",
      "frame: 19081\n",
      "\tboxes: 7\n",
      "frame: 19101\n",
      "\tboxes: 6\n",
      "frame: 19121\n",
      "\tboxes: 6\n",
      "frame: 19141\n",
      "\tboxes: 6\n",
      "frame: 19161\n",
      "\tboxes: 6\n",
      "frame: 19181\n",
      "\tboxes: 6\n",
      "frame: 19201\n",
      "\tboxes: 7\n",
      "frame: 19221\n",
      "\tboxes: 6\n",
      "frame: 19241\n",
      "\tboxes: 7\n",
      "frame: 19261\n",
      "\tboxes: 8\n",
      "frame: 19281\n",
      "\tboxes: 7\n",
      "frame: 19301\n",
      "\tboxes: 6\n",
      "frame: 19321\n",
      "\tboxes: 7\n",
      "frame: 19341\n",
      "\tboxes: 7\n",
      "frame: 19361\n",
      "\tboxes: 6\n",
      "frame: 19381\n",
      "\tboxes: 6\n",
      "frame: 19401\n",
      "\tboxes: 6\n",
      "frame: 19421\n",
      "\tboxes: 6\n",
      "frame: 19441\n",
      "\tboxes: 6\n",
      "frame: 19461\n",
      "\tboxes: 6\n",
      "frame: 19481\n",
      "\tboxes: 6\n",
      "frame: 19501\n",
      "\tboxes: 6\n",
      "frame: 19521\n",
      "\tboxes: 6\n",
      "frame: 19541\n",
      "\tboxes: 7\n",
      "frame: 19561\n",
      "\tboxes: 6\n",
      "frame: 19581\n",
      "\tboxes: 6\n",
      "frame: 19601\n",
      "\tboxes: 7\n",
      "frame: 19621\n",
      "\tboxes: 7\n",
      "frame: 19641\n",
      "\tboxes: 6\n",
      "frame: 19661\n",
      "\tboxes: 6\n",
      "frame: 19681\n",
      "\tboxes: 5\n",
      "frame: 19701\n",
      "\tboxes: 6\n",
      "frame: 19721\n",
      "\tboxes: 7\n",
      "frame: 19741\n",
      "\tboxes: 7\n",
      "frame: 19761\n",
      "\tboxes: 7\n",
      "frame: 19781\n",
      "\tboxes: 7\n",
      "frame: 19801\n",
      "\tboxes: 7\n",
      "frame: 19821\n",
      "\tboxes: 7\n",
      "frame: 19841\n",
      "\tboxes: 8\n",
      "frame: 19861\n",
      "\tboxes: 8\n",
      "frame: 19881\n",
      "\tboxes: 7\n",
      "frame: 19901\n",
      "\tboxes: 8\n",
      "frame: 19921\n",
      "\tboxes: 7\n",
      "frame: 19941\n",
      "\tboxes: 7\n",
      "frame: 19961\n",
      "\tboxes: 7\n",
      "frame: 19981\n",
      "\tboxes: 7\n",
      "frame: 20001\n",
      "\tboxes: 7\n",
      "frame: 20021\n",
      "\tboxes: 7\n",
      "frame: 20041\n",
      "\tboxes: 7\n",
      "frame: 20061\n",
      "\tboxes: 7\n",
      "frame: 20081\n",
      "\tboxes: 7\n",
      "frame: 20101\n",
      "\tboxes: 6\n",
      "frame: 20121\n",
      "\tboxes: 7\n",
      "frame: 20141\n",
      "\tboxes: 7\n",
      "frame: 20161\n",
      "\tboxes: 7\n",
      "frame: 20181\n",
      "\tboxes: 6\n",
      "frame: 20201\n",
      "\tboxes: 6\n",
      "frame: 20221\n",
      "\tboxes: 8\n",
      "frame: 20241\n",
      "\tboxes: 10\n",
      "frame: 20261\n",
      "\tboxes: 10\n",
      "frame: 20281\n",
      "\tboxes: 8\n",
      "frame: 20301\n",
      "\tboxes: 9\n",
      "frame: 20321\n",
      "\tboxes: 9\n",
      "frame: 20341\n",
      "\tboxes: 10\n",
      "frame: 20361\n",
      "\tboxes: 10\n",
      "frame: 20381\n",
      "frame: 20401\n",
      "frame: 20421\n",
      "frame: 20441\n",
      "\tboxes: 10\n",
      "frame: 20461\n",
      "\tboxes: 9\n",
      "frame: 20481\n",
      "\tboxes: 9\n",
      "frame: 20501\n",
      "\tboxes: 9\n",
      "frame: 20521\n",
      "\tboxes: 9\n",
      "frame: 20541\n",
      "\tboxes: 10\n",
      "frame: 20561\n",
      "\tboxes: 9\n",
      "frame: 20581\n",
      "\tboxes: 8\n",
      "frame: 20601\n",
      "\tboxes: 9\n",
      "frame: 20621\n",
      "\tboxes: 9\n",
      "frame: 20641\n",
      "\tboxes: 9\n",
      "frame: 20661\n",
      "\tboxes: 8\n",
      "frame: 20681\n",
      "\tboxes: 9\n",
      "frame: 20701\n",
      "\tboxes: 9\n",
      "frame: 20721\n",
      "\tboxes: 10\n",
      "frame: 20741\n",
      "\tboxes: 9\n",
      "frame: 20761\n",
      "\tboxes: 9\n",
      "frame: 20781\n",
      "\tboxes: 9\n",
      "frame: 20801\n",
      "\tboxes: 11\n",
      "frame: 20821\n",
      "\tboxes: 10\n",
      "frame: 20841\n",
      "\tboxes: 10\n",
      "frame: 20861\n",
      "\tboxes: 10\n",
      "frame: 20881\n",
      "\tboxes: 11\n",
      "frame: 20901\n",
      "\tboxes: 11\n",
      "frame: 20921\n",
      "\tboxes: 11\n",
      "frame: 20941\n",
      "\tboxes: 10\n",
      "frame: 20961\n",
      "\tboxes: 10\n",
      "frame: 20981\n",
      "\tboxes: 9\n",
      "frame: 21001\n",
      "\tboxes: 9\n",
      "frame: 21021\n",
      "\tboxes: 10\n",
      "frame: 21041\n",
      "\tboxes: 9\n",
      "frame: 21061\n",
      "\tboxes: 10\n",
      "frame: 21081\n",
      "\tboxes: 9\n",
      "frame: 21101\n",
      "\tboxes: 9\n",
      "frame: 21121\n",
      "\tboxes: 9\n",
      "frame: 21141\n",
      "\tboxes: 9\n",
      "frame: 21161\n",
      "\tboxes: 8\n",
      "frame: 21181\n",
      "\tboxes: 9\n",
      "frame: 21201\n",
      "\tboxes: 8\n",
      "frame: 21221\n",
      "\tboxes: 8\n",
      "frame: 21241\n",
      "\tboxes: 8\n",
      "frame: 21261\n",
      "\tboxes: 9\n",
      "frame: 21281\n",
      "\tboxes: 9\n",
      "frame: 21301\n",
      "\tboxes: 9\n",
      "frame: 21321\n",
      "\tboxes: 9\n",
      "frame: 21341\n",
      "\tboxes: 9\n",
      "frame: 21361\n",
      "\tboxes: 9\n",
      "frame: 21381\n",
      "\tboxes: 9\n",
      "frame: 21401\n",
      "\tboxes: 11\n",
      "frame: 21421\n",
      "\tboxes: 11\n",
      "frame: 21441\n",
      "\tboxes: 10\n",
      "frame: 21461\n",
      "\tboxes: 10\n",
      "frame: 21481\n",
      "\tboxes: 10\n",
      "frame: 21501\n",
      "\tboxes: 10\n",
      "frame: 21521\n",
      "\tboxes: 11\n",
      "frame: 21541\n",
      "\tboxes: 10\n",
      "frame: 21561\n",
      "\tboxes: 10\n",
      "frame: 21581\n",
      "\tboxes: 10\n",
      "frame: 21601\n",
      "\tboxes: 11\n",
      "frame: 21621\n",
      "\tboxes: 10\n",
      "frame: 21641\n",
      "\tboxes: 11\n",
      "frame: 21661\n",
      "\tboxes: 11\n",
      "frame: 21681\n",
      "\tboxes: 10\n",
      "frame: 21701\n",
      "\tboxes: 9\n",
      "frame: 21721\n",
      "\tboxes: 9\n",
      "frame: 21741\n",
      "\tboxes: 9\n",
      "frame: 21761\n",
      "\tboxes: 9\n",
      "frame: 21781\n",
      "\tboxes: 9\n",
      "frame: 21801\n",
      "\tboxes: 9\n",
      "frame: 21821\n",
      "\tboxes: 9\n",
      "frame: 21841\n",
      "\tboxes: 9\n",
      "frame: 21861\n",
      "\tboxes: 10\n",
      "frame: 21881\n",
      "\tboxes: 9\n",
      "frame: 21901\n",
      "\tboxes: 9\n",
      "frame: 21921\n",
      "\tboxes: 11\n",
      "frame: 21941\n",
      "\tboxes: 9\n",
      "frame: 21961\n",
      "\tboxes: 11\n",
      "frame: 21981\n",
      "\tboxes: 10\n",
      "frame: 22001\n",
      "\tboxes: 12\n",
      "frame: 22021\n",
      "\tboxes: 9\n",
      "frame: 22041\n",
      "\tboxes: 8\n",
      "frame: 22061\n",
      "\tboxes: 8\n",
      "frame: 22081\n",
      "\tboxes: 8\n",
      "frame: 22101\n",
      "\tboxes: 9\n",
      "frame: 22121\n",
      "\tboxes: 9\n",
      "frame: 22141\n",
      "\tboxes: 8\n",
      "frame: 22161\n",
      "\tboxes: 9\n",
      "frame: 22181\n",
      "\tboxes: 8\n",
      "frame: 22201\n",
      "\tboxes: 9\n",
      "frame: 22221\n",
      "\tboxes: 9\n",
      "frame: 22241\n",
      "\tboxes: 9\n",
      "frame: 22261\n",
      "\tboxes: 10\n",
      "frame: 22281\n",
      "\tboxes: 10\n",
      "frame: 22301\n",
      "\tboxes: 9\n",
      "frame: 22321\n",
      "\tboxes: 11\n",
      "frame: 22341\n",
      "\tboxes: 9\n",
      "frame: 22361\n",
      "\tboxes: 11\n",
      "frame: 22381\n",
      "\tboxes: 10\n",
      "frame: 22401\n",
      "\tboxes: 10\n",
      "frame: 22421\n",
      "\tboxes: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame: 22441\n",
      "\tboxes: 11\n",
      "frame: 22461\n",
      "\tboxes: 11\n",
      "frame: 22481\n",
      "\tboxes: 8\n",
      "frame: 22501\n",
      "\tboxes: 9\n",
      "frame: 22521\n",
      "\tboxes: 10\n",
      "frame: 22541\n",
      "\tboxes: 9\n",
      "frame: 22561\n",
      "\tboxes: 9\n",
      "frame: 22581\n",
      "\tboxes: 9\n",
      "frame: 22601\n",
      "\tboxes: 9\n",
      "frame: 22621\n",
      "\tboxes: 8\n",
      "frame: 22641\n",
      "\tboxes: 9\n",
      "frame: 22661\n",
      "\tboxes: 8\n",
      "frame: 22681\n",
      "\tboxes: 9\n",
      "frame: 22701\n",
      "\tboxes: 9\n",
      "frame: 22721\n",
      "\tboxes: 10\n",
      "frame: 22741\n",
      "\tboxes: 10\n",
      "frame: 22761\n",
      "\tboxes: 9\n",
      "frame: 22781\n",
      "\tboxes: 9\n",
      "frame: 22801\n",
      "\tboxes: 9\n",
      "frame: 22821\n",
      "\tboxes: 8\n",
      "frame: 22841\n",
      "\tboxes: 7\n",
      "frame: 22861\n",
      "\tboxes: 7\n",
      "frame: 22881\n",
      "\tboxes: 7\n",
      "frame: 22901\n",
      "\tboxes: 7\n",
      "frame: 22921\n",
      "\tboxes: 8\n",
      "frame: 22941\n",
      "\tboxes: 8\n",
      "frame: 22961\n",
      "\tboxes: 9\n",
      "frame: 22981\n",
      "\tboxes: 8\n",
      "frame: 23001\n",
      "\tboxes: 8\n",
      "frame: 23021\n",
      "\tboxes: 9\n",
      "frame: 23041\n",
      "\tboxes: 10\n",
      "frame: 23061\n",
      "\tboxes: 10\n",
      "frame: 23081\n",
      "\tboxes: 11\n",
      "frame: 23101\n",
      "\tboxes: 10\n",
      "frame: 23121\n",
      "\tboxes: 9\n",
      "frame: 23141\n",
      "\tboxes: 9\n",
      "frame: 23161\n",
      "\tboxes: 10\n",
      "frame: 23181\n",
      "frame: 23201\n",
      "frame: 23221\n",
      "frame: 23241\n",
      "\tboxes: 10\n",
      "frame: 23261\n",
      "\tboxes: 8\n",
      "frame: 23281\n",
      "\tboxes: 10\n",
      "frame: 23301\n",
      "\tboxes: 13\n",
      "frame: 23321\n",
      "\tboxes: 10\n",
      "frame: 23341\n",
      "\tboxes: 7\n",
      "frame: 23361\n",
      "\tboxes: 7\n",
      "frame: 23381\n",
      "\tboxes: 8\n",
      "frame: 23401\n",
      "\tboxes: 9\n",
      "frame: 23421\n",
      "\tboxes: 9\n",
      "frame: 23441\n",
      "\tboxes: 9\n",
      "frame: 23461\n",
      "\tboxes: 8\n",
      "frame: 23481\n",
      "\tboxes: 10\n",
      "frame: 23501\n",
      "\tboxes: 9\n",
      "frame: 23521\n",
      "\tboxes: 10\n",
      "frame: 23541\n",
      "\tboxes: 9\n",
      "frame: 23561\n",
      "\tboxes: 8\n",
      "frame: 23581\n",
      "\tboxes: 8\n",
      "frame: 23601\n",
      "\tboxes: 8\n",
      "frame: 23621\n",
      "\tboxes: 9\n",
      "frame: 23641\n",
      "\tboxes: 9\n",
      "frame: 23661\n",
      "\tboxes: 9\n",
      "frame: 23681\n",
      "\tboxes: 9\n",
      "frame: 23701\n",
      "\tboxes: 8\n",
      "frame: 23721\n",
      "\tboxes: 9\n",
      "frame: 23741\n",
      "\tboxes: 8\n",
      "frame: 23761\n",
      "\tboxes: 8\n",
      "frame: 23781\n",
      "\tboxes: 7\n",
      "frame: 23801\n",
      "\tboxes: 7\n",
      "frame: 23821\n",
      "\tboxes: 8\n",
      "frame: 23841\n",
      "\tboxes: 8\n",
      "frame: 23861\n",
      "\tboxes: 8\n",
      "frame: 23881\n",
      "\tboxes: 9\n",
      "frame: 23901\n",
      "\tboxes: 8\n",
      "frame: 23921\n",
      "\tboxes: 8\n",
      "frame: 23941\n",
      "\tboxes: 8\n",
      "frame: 23961\n",
      "\tboxes: 8\n",
      "frame: 23981\n",
      "\tboxes: 9\n",
      "frame: 24001\n",
      "\tboxes: 8\n",
      "frame: 24021\n",
      "\tboxes: 9\n",
      "frame: 24041\n",
      "\tboxes: 10\n",
      "frame: 24061\n",
      "\tboxes: 10\n",
      "frame: 24081\n",
      "\tboxes: 9\n",
      "frame: 24101\n",
      "\tboxes: 9\n",
      "frame: 24121\n",
      "\tboxes: 9\n",
      "frame: 24141\n",
      "\tboxes: 8\n",
      "frame: 24161\n",
      "\tboxes: 10\n",
      "frame: 24181\n",
      "\tboxes: 10\n",
      "frame: 24201\n",
      "\tboxes: 11\n",
      "frame: 24221\n",
      "\tboxes: 10\n",
      "frame: 24241\n",
      "\tboxes: 10\n",
      "frame: 24261\n",
      "\tboxes: 9\n",
      "frame: 24281\n",
      "\tboxes: 9\n",
      "frame: 24301\n",
      "\tboxes: 9\n",
      "frame: 24321\n",
      "\tboxes: 10\n",
      "frame: 24341\n",
      "\tboxes: 8\n",
      "frame: 24361\n",
      "\tboxes: 7\n",
      "frame: 24381\n",
      "\tboxes: 8\n",
      "frame: 24401\n",
      "\tboxes: 9\n",
      "frame: 24421\n",
      "\tboxes: 9\n",
      "frame: 24441\n",
      "\tboxes: 9\n",
      "frame: 24461\n",
      "\tboxes: 10\n",
      "frame: 24481\n",
      "\tboxes: 10\n",
      "frame: 24501\n",
      "\tboxes: 8\n",
      "frame: 24521\n",
      "\tboxes: 11\n",
      "frame: 24541\n",
      "\tboxes: 10\n",
      "frame: 24561\n",
      "\tboxes: 10\n",
      "frame: 24581\n",
      "\tboxes: 9\n",
      "frame: 24601\n",
      "\tboxes: 9\n",
      "frame: 24621\n",
      "\tboxes: 10\n",
      "frame: 24641\n",
      "\tboxes: 10\n",
      "frame: 24661\n",
      "\tboxes: 10\n",
      "frame: 24681\n",
      "\tboxes: 9\n",
      "frame: 24701\n",
      "\tboxes: 7\n",
      "frame: 24721\n",
      "\tboxes: 9\n",
      "frame: 24741\n",
      "\tboxes: 7\n",
      "frame: 24761\n",
      "\tboxes: 7\n",
      "frame: 24781\n",
      "\tboxes: 7\n",
      "frame: 24801\n",
      "\tboxes: 8\n",
      "frame: 24821\n",
      "\tboxes: 7\n",
      "frame: 24841\n",
      "\tboxes: 7\n",
      "frame: 24861\n",
      "\tboxes: 8\n",
      "frame: 24881\n",
      "\tboxes: 8\n",
      "frame: 24901\n",
      "\tboxes: 8\n",
      "frame: 24921\n",
      "frame: 24941\n",
      "frame: 24961\n",
      "frame: 24981\n",
      "\tboxes: 8\n",
      "frame: 25001\n",
      "\tboxes: 9\n",
      "frame: 25021\n",
      "\tboxes: 9\n",
      "frame: 25041\n",
      "\tboxes: 9\n",
      "frame: 25061\n",
      "\tboxes: 8\n",
      "frame: 25081\n",
      "\tboxes: 9\n",
      "frame: 25101\n",
      "\tboxes: 9\n",
      "frame: 25121\n",
      "\tboxes: 9\n",
      "frame: 25141\n",
      "\tboxes: 8\n",
      "frame: 25161\n",
      "\tboxes: 9\n",
      "frame: 25181\n",
      "\tboxes: 9\n",
      "frame: 25201\n",
      "\tboxes: 9\n",
      "frame: 25221\n",
      "\tboxes: 10\n",
      "frame: 25241\n",
      "\tboxes: 10\n",
      "frame: 25261\n",
      "\tboxes: 12\n",
      "frame: 25281\n",
      "\tboxes: 11\n",
      "frame: 25301\n",
      "\tboxes: 11\n",
      "frame: 25321\n",
      "\tboxes: 12\n",
      "frame: 25341\n",
      "\tboxes: 11\n",
      "frame: 25361\n",
      "\tboxes: 8\n",
      "frame: 25381\n",
      "\tboxes: 10\n",
      "frame: 25401\n",
      "\tboxes: 9\n",
      "frame: 25421\n",
      "\tboxes: 11\n",
      "frame: 25441\n",
      "\tboxes: 9\n",
      "frame: 25461\n",
      "\tboxes: 10\n",
      "frame: 25481\n",
      "\tboxes: 10\n",
      "frame: 25501\n",
      "\tboxes: 9\n",
      "frame: 25521\n",
      "\tboxes: 11\n",
      "frame: 25541\n",
      "\tboxes: 11\n",
      "frame: 25561\n",
      "\tboxes: 11\n",
      "frame: 25581\n",
      "\tboxes: 13\n",
      "frame: 25601\n",
      "\tboxes: 12\n",
      "frame: 25621\n",
      "\tboxes: 12\n",
      "frame: 25641\n",
      "\tboxes: 12\n",
      "frame: 25661\n",
      "\tboxes: 12\n",
      "frame: 25681\n",
      "\tboxes: 14\n",
      "frame: 25701\n",
      "\tboxes: 11\n",
      "frame: 25721\n",
      "\tboxes: 12\n",
      "frame: 25741\n",
      "\tboxes: 11\n",
      "frame: 25761\n",
      "\tboxes: 12\n",
      "frame: 25781\n",
      "\tboxes: 11\n",
      "frame: 25801\n",
      "\tboxes: 12\n",
      "frame: 25821\n",
      "\tboxes: 11\n",
      "frame: 25841\n",
      "\tboxes: 12\n",
      "frame: 25861\n",
      "\tboxes: 11\n",
      "frame: 25881\n",
      "\tboxes: 11\n",
      "frame: 25901\n",
      "\tboxes: 11\n",
      "frame: 25921\n",
      "\tboxes: 10\n",
      "frame: 25941\n",
      "\tboxes: 10\n",
      "frame: 25961\n",
      "\tboxes: 10\n",
      "frame: 25981\n",
      "\tboxes: 9\n",
      "frame: 26001\n",
      "\tboxes: 9\n",
      "frame: 26021\n",
      "\tboxes: 9\n",
      "frame: 26041\n",
      "\tboxes: 10\n",
      "frame: 26061\n",
      "\tboxes: 8\n",
      "frame: 26081\n",
      "\tboxes: 9\n",
      "frame: 26101\n",
      "\tboxes: 9\n",
      "frame: 26121\n",
      "\tboxes: 8\n",
      "frame: 26141\n",
      "\tboxes: 9\n",
      "frame: 26161\n",
      "\tboxes: 9\n",
      "frame: 26181\n",
      "\tboxes: 10\n",
      "frame: 26201\n",
      "\tboxes: 10\n",
      "frame: 26221\n",
      "\tboxes: 9\n",
      "frame: 26241\n",
      "\tboxes: 10\n",
      "frame: 26261\n",
      "\tboxes: 8\n",
      "frame: 26281\n",
      "\tboxes: 9\n",
      "frame: 26301\n",
      "\tboxes: 12\n",
      "frame: 26321\n",
      "\tboxes: 11\n",
      "frame: 26341\n",
      "\tboxes: 10\n",
      "frame: 26361\n",
      "\tboxes: 10\n",
      "frame: 26381\n",
      "\tboxes: 8\n",
      "frame: 26401\n",
      "\tboxes: 9\n",
      "frame: 26421\n",
      "\tboxes: 10\n",
      "frame: 26441\n",
      "\tboxes: 10\n",
      "frame: 26461\n",
      "\tboxes: 9\n",
      "frame: 26481\n",
      "\tboxes: 9\n",
      "frame: 26501\n",
      "\tboxes: 9\n",
      "frame: 26521\n",
      "\tboxes: 8\n",
      "frame: 26541\n",
      "\tboxes: 11\n",
      "frame: 26561\n",
      "\tboxes: 8\n",
      "frame: 26581\n",
      "\tboxes: 8\n",
      "frame: 26601\n",
      "\tboxes: 8\n",
      "frame: 26621\n",
      "\tboxes: 10\n",
      "frame: 26641\n",
      "\tboxes: 9\n",
      "frame: 26661\n",
      "\tboxes: 8\n",
      "frame: 26681\n",
      "\tboxes: 9\n",
      "frame: 26701\n",
      "\tboxes: 10\n",
      "frame: 26721\n",
      "\tboxes: 10\n",
      "frame: 26741\n",
      "\tboxes: 11\n",
      "--- True 24660.0 962.0674429237843 1208.0\n",
      "Saving Results...\n"
     ]
    }
   ],
   "source": [
    "anomalies = full_run_single(video_id, video_dir, static_dir, frame_by_frame_results_dir, static_results_dir, crop_boxes_dir, \n",
    "                            ignore_mask_dir, detector_config_path, detector_model_path, reid_model_path, reid_model_backbone,\n",
    "                            crop_results_dir, anomaly_results_dir, ignore_area_thresh=500, anomaly_thresh=0.5\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating background...\n",
      "Detecting raw video...\n",
      "Detecting background...\n",
      "Creating ingore mask...\n",
      "total frames: 26760, framerate: 30.0, height: 410, width: 800\n",
      "-------------------------\n",
      "generated: 1\n",
      "frame: 1\n",
      "\tboxes: 9\n",
      "generated: 21\n",
      "frame: 21\n",
      "\tboxes: 9\n",
      "generated: 41\n",
      "frame: 41\n",
      "\tboxes: 10\n",
      "generated: 61\n",
      "frame: 61\n",
      "\tboxes: 9\n",
      "generated: 81\n",
      "frame: 81\n",
      "\tboxes: 8\n",
      "generated: 101\n",
      "frame: 101\n",
      "\tboxes: 8\n",
      "generated: 121\n",
      "frame: 121\n",
      "\tboxes: 8\n",
      "generated: 141\n",
      "frame: 141\n",
      "\tboxes: 7\n",
      "generated: 161\n",
      "frame: 161\n",
      "\tboxes: 6\n",
      "generated: 181\n",
      "frame: 181\n",
      "\tboxes: 6\n",
      "generated: 201\n",
      "frame: 201\n",
      "\tboxes: 6\n",
      "generated: 221\n",
      "frame: 221\n",
      "\tboxes: 6\n",
      "generated: 241\n",
      "frame: 241\n",
      "\tboxes: 6\n",
      "generated: 261\n",
      "frame: 261\n",
      "\tboxes: 7\n",
      "generated: 281\n",
      "frame: 281\n",
      "\tboxes: 7\n",
      "generated: 301\n",
      "frame: 301\n",
      "\tboxes: 5\n",
      "generated: 321\n",
      "frame: 321\n",
      "\tboxes: 5\n",
      "generated: 341\n",
      "frame: 341\n",
      "\tboxes: 5\n",
      "generated: 361\n",
      "frame: 361\n",
      "\tboxes: 4\n",
      "generated: 381\n",
      "frame: 381\n",
      "\tboxes: 4\n",
      "generated: 401\n",
      "frame: 401\n",
      "\tboxes: 4\n",
      "generated: 421\n",
      "frame: 421\n",
      "\tboxes: 4\n",
      "generated: 441\n",
      "frame: 441\n",
      "\tboxes: 4\n",
      "generated: 461\n",
      "frame: 461\n",
      "\tboxes: 4\n",
      "generated: 481\n",
      "frame: 481\n",
      "\tboxes: 4\n",
      "generated: 501\n",
      "frame: 501\n",
      "\tboxes: 4\n",
      "generated: 521\n",
      "frame: 521\n",
      "\tboxes: 2\n",
      "generated: 541\n",
      "frame: 541\n",
      "\tboxes: 2\n",
      "generated: 561\n",
      "frame: 561\n",
      "\tboxes: 2\n",
      "generated: 581\n",
      "frame: 581\n",
      "\tboxes: 2\n",
      "generated: 601\n",
      "frame: 601\n",
      "\tboxes: 2\n",
      "generated: 621\n",
      "frame: 621\n",
      "\tboxes: 2\n",
      "generated: 641\n",
      "frame: 641\n",
      "\tboxes: 2\n",
      "generated: 661\n",
      "frame: 661\n",
      "\tboxes: 2\n",
      "generated: 681\n",
      "frame: 681\n",
      "\tboxes: 2\n",
      "generated: 701\n",
      "frame: 701\n",
      "\tboxes: 2\n",
      "generated: 721\n",
      "frame: 721\n",
      "\tboxes: 2\n",
      "generated: 741\n",
      "frame: 741\n",
      "\tboxes: 1\n",
      "generated: 761\n",
      "frame: 761\n",
      "\tboxes: 1\n",
      "generated: 781\n",
      "frame: 781\n",
      "\tboxes: 1\n",
      "generated: 801\n",
      "frame: 801\n",
      "\tboxes: 1\n",
      "generated: 821\n",
      "frame: 821\n",
      "\tboxes: 1\n",
      "generated: 841\n",
      "frame: 841\n",
      "\tboxes: 1\n",
      "generated: 861\n",
      "frame: 861\n",
      "\tboxes: 1\n",
      "generated: 881\n",
      "frame: 881\n",
      "\tboxes: 1\n",
      "generated: 901\n",
      "frame: 901\n",
      "\tboxes: 1\n",
      "generated: 921\n",
      "frame: 921\n",
      "\tboxes: 1\n",
      "generated: 941\n",
      "frame: 941\n",
      "\tboxes: 1\n",
      "generated: 961\n",
      "frame: 961\n",
      "\tboxes: 1\n",
      "generated: 981\n",
      "frame: 981\n",
      "\tboxes: 1\n",
      "generated: 1001\n",
      "frame: 1001\n",
      "\tboxes: 1\n",
      "generated: 1021\n",
      "frame: 1021\n",
      "\tboxes: 1\n",
      "generated: 1041\n",
      "frame: 1041\n",
      "\tboxes: 1\n",
      "generated: 1061\n",
      "frame: 1061\n",
      "\tboxes: 1\n",
      "generated: 1081\n",
      "frame: 1081\n",
      "\tboxes: 1\n",
      "generated: 1101\n",
      "frame: 1101\n",
      "\tboxes: 1\n",
      "generated: 1121\n",
      "frame: 1121\n",
      "\tboxes: 1\n",
      "generated: 1141\n",
      "frame: 1141\n",
      "\tboxes: 1\n",
      "generated: 1161\n",
      "frame: 1161\n",
      "\tboxes: 1\n",
      "generated: 1181\n",
      "frame: 1181\n",
      "\tboxes: 1\n",
      "generated: 1201\n",
      "frame: 1201\n",
      "\tboxes: 1\n",
      "generated: 1221\n",
      "frame: 1221\n",
      "\tboxes: 1\n",
      "generated: 1241\n",
      "frame: 1241\n",
      "\tboxes: 1\n",
      "generated: 1261\n",
      "frame: 1261\n",
      "\tboxes: 1\n",
      "generated: 1281\n",
      "frame: 1281\n",
      "\tboxes: 1\n",
      "generated: 1301\n",
      "frame: 1301\n",
      "\tboxes: 1\n",
      "generated: 1321\n",
      "frame: 1321\n",
      "\tboxes: 1\n",
      "generated: 1341\n",
      "frame: 1341\n",
      "\tboxes: 1\n",
      "generated: 1361\n",
      "frame: 1361\n",
      "\tboxes: 1\n",
      "generated: 1381\n",
      "frame: 1381\n",
      "\tboxes: 1\n",
      "generated: 1401\n",
      "frame: 1401\n",
      "\tboxes: 1\n",
      "generated: 1421\n",
      "frame: 1421\n",
      "\tboxes: 1\n",
      "generated: 1441\n",
      "frame: 1441\n",
      "\tboxes: 1\n",
      "generated: 1461\n",
      "frame: 1461\n",
      "\tboxes: 1\n",
      "generated: 1481\n",
      "frame: 1481\n",
      "\tboxes: 1\n",
      "generated: 1501\n",
      "frame: 1501\n",
      "\tboxes: 1\n",
      "generated: 1521\n",
      "frame: 1521\n",
      "\tboxes: 1\n",
      "generated: 1541\n",
      "frame: 1541\n",
      "\tboxes: 1\n",
      "generated: 1561\n",
      "frame: 1561\n",
      "\tboxes: 1\n",
      "generated: 1581\n",
      "frame: 1581\n",
      "\tboxes: 1\n",
      "generated: 1601\n",
      "frame: 1601\n",
      "\tboxes: 1\n",
      "generated: 1621\n",
      "frame: 1621\n",
      "\tboxes: 1\n",
      "generated: 1641\n",
      "frame: 1641\n",
      "\tboxes: 1\n",
      "generated: 1661\n",
      "frame: 1661\n",
      "\tboxes: 1\n",
      "generated: 1681\n",
      "frame: 1681\n",
      "\tboxes: 1\n",
      "generated: 1701\n",
      "frame: 1701\n",
      "\tboxes: 1\n",
      "generated: 1721\n",
      "frame: 1721\n",
      "\tboxes: 1\n",
      "generated: 1741\n",
      "frame: 1741\n",
      "\tboxes: 1\n",
      "generated: 1761\n",
      "frame: 1761\n",
      "\tboxes: 1\n",
      "generated: 1781\n",
      "frame: 1781\n",
      "\tboxes: 1\n",
      "generated: 1801\n",
      "frame: 1801\n",
      "\tboxes: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-3587f2cfa907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m anomalies = full_run_sequential(video_id, video_dir, static_dir, frame_by_frame_results_dir, static_results_dir, crop_boxes_dir, \n\u001b[1;32m      2\u001b[0m                             \u001b[0mignore_mask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_config_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreid_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreid_model_backbone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                             \u001b[0mcrop_results_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomaly_results_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_area_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomaly_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                            )\n",
      "\u001b[0;32m<ipython-input-59-b9df4ce207ad>\u001b[0m in \u001b[0;36mfull_run_sequential\u001b[0;34m(video_id, video_dir, static_dir, frame_by_frame_results_dir, static_results_dir, crop_boxes_dir, ignore_mask_dir, detector_config_path, detector_model_path, reid_model_path, reid_model_backbone, crop_results_dir, anomaly_results_dir, bg_interval, bg_alpha, bg_start_frame, bg_threshold, raw_detect_interval, crop_min_obj_size, crop_row_capacity, crop_box_aspect_ratio, ignore_count_thresh, ignore_area_thresh, ignore_score_thresh, ignore_gau_sigma, abnormal_duration_thresh, detect_duration_thresh, undetect_duration_thresh, bbox_score_thresh, light_thresh, anomaly_thresh, similarity_thresh, suspicious_duration_thresh, detector_verbose_interval, verbose)\u001b[0m\n\u001b[1;32m     64\u001b[0m                         \u001b[0mreid_model_backbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_start_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabnormal_duration_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetect_duration_thresh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                         \u001b[0mundetect_duration_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_score_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlight_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomaly_thresh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                         similarity_thresh, suspicious_duration_thresh, verbose)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-9d6951c3628c>\u001b[0m in \u001b[0;36mget_anomalies_sequential\u001b[0;34m(video_reader, reid_model_path, fbf_results_dict, static_results_dict, ignore_matrix_gen, reid_model_name, start_frame, frame_interval, abnormal_duration_thresh, detect_thresh, undetect_thresh, score_thresh, light_thresh, anomaly_score_thresh, similarity_thresh, suspicious_time_thresh, verbose)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0manomaly_now\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mignore_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_matrix_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# create tmp_score, tmp_detect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-8b955f222aa2>\u001b[0m in \u001b[0;36mcreate_ignore_mask_generator\u001b[0;34m(fbf_results, img_shape, count_threshold, area_threshold, score_threshold, gaussian_sigma, alpha)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mrunning_heatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbf_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Maybe have an alpha like how background images are made?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mrunning_heatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrunning_heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-47116a1fea2d>\u001b[0m in \u001b[0;36miterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generated:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-0ccc98efb44b>\u001b[0m in \u001b[0;36mdetect_images_generator\u001b[0;34m(self, images, frames, crop_boxes, verbose)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \"\"\"\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-b9df4ce207ad>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating background...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mbg_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_video\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_start_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mbg_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbg_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# throw out frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7abbff226dca>\u001b[0m in \u001b[0;36mcalc_background\u001b[0;34m(images, interval, alpha, start_frame, threshold)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mrunning_bg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprev_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrunning_bg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# initial image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mrunning_bg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0ec18c8bc1cc>\u001b[0m in \u001b[0;36mread_frames\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframe_nums\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mvid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mhas_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "anomalies = full_run_sequential(video_id, video_dir, static_dir, frame_by_frame_results_dir, static_results_dir, crop_boxes_dir, \n",
    "                            ignore_mask_dir, detector_config_path, detector_model_path, reid_model_path, reid_model_backbone,\n",
    "                            crop_results_dir, anomaly_results_dir, ignore_area_thresh=500, anomaly_thresh=0.5, bg_interval=20,\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anomalies, anomaly_times = process_folder(video_dir, static_dir, frame_by_frame_results_dir, static_results_dir, crop_boxes_dir, \n",
    "                            ignore_mask_dir, ssd_config_path, ssd_model_path, reid_model_path, reid_model_backbone,\n",
    "                            crop_results_dir, anomaly_results_dir, ignore_area_thresh=500, anomaly_thresh=0.5, bg_interval=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_matrices(mat_detected, mat_undetected, mat_start, mat_end, mat_score, mat_state, frame, ignore_mask, boxes, box_score_thresh=0.3, time_tresh, score_thresh, undetected_thresh):\n",
    "    \"\"\"\n",
    "    Update algorithm identical to paper, doesnt actually work.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def get_connected_region(mat, pos):\n",
    "        regions = label(mat, connectivity=1)\n",
    "        return regions == regions[pos]\n",
    "    \n",
    "    def mask(mat, mask):\n",
    "        return mat * mask\n",
    "    \n",
    "    \n",
    "    \n",
    "    h, w = mat_detected.shape\n",
    "    \n",
    "    tmp_mat_detected = np.zeros((h, w))\n",
    "    tmp_mat_score = np.zeros((h, w))\n",
    "    \n",
    "    for (x1, y1, x2, y2), score in boxes:\n",
    "        if score > box_score_thresh:\n",
    "            tmp_mat_detected[y1:y2, x1:x2] = 1\n",
    "            tmp_mat_score[y1:y2, x1:x2] = np.maximum(tmp_mat_detected[y1:y2, x1:x2], score) # max will never be score?\n",
    "\n",
    "            \n",
    "    tmp_mat_undetected = mask(1 - tmp_mat_score, ignore_mask)\n",
    "    tmp_mat_detected = mask(tmp_mat_detected, ignore_mask)\n",
    "    tmp_mat_score = mask(tmp_mat_score, ignore_mask)\n",
    "    \n",
    "    mat_detected = mat_detected + tmp_mat_detected\n",
    "    mat_score = mat_score + tmp_mat_score\n",
    "    mat_undetected = mat_undetected + tmp_mat_undetected\n",
    "    mat_undetected[tmp_mat_detected] = 0\n",
    "    \n",
    "    mat_start[mat_detected == 1] = frame\n",
    "    mat_end[mat_detected > 0] = frame\n",
    "    \n",
    "    tmp_mat_delay = mat_end - mat_start\n",
    "    pos = argmax(tmp_mat_delay)\n",
    "    \n",
    "    if tmp_mat_delay[pos] > time_thresh:\n",
    "        tmp_mat_binary = mat_detected[pos] - mat_detected <= 1\n",
    "        anomaly_region = get_connected_region(tmp_mat_binary, pos)\n",
    "        \n",
    "        if mat_score / mat_undetected > score_thresh:\n",
    "            # start or keep anomaly status\n",
    "            \n",
    "        if mat_undetected[pos] > undetected_thresh:\n",
    "            # finish anomaly, output anomaly information\n",
    "            \n",
    "            \n",
    "    mat_state[mat_detected > detected_thresh] = True\n",
    "    mat_state[mat_undetected > undetected_thresh] = False\n",
    "    \n",
    "    mat_detected[tmp_mat_detected | mat_state] = False\n",
    "    mat_score[tmp_mat_detected | mat_state] = False\n",
    "    \n",
    "    return mat_detected, mat_undetected, mat_start, mat_end, mat_score, mat_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Notes\n",
    "\n",
    "+ Video with gaps in them, (eg frames are black, no data) that happen during an anomaly, will create 2 separate anomaly events, or cause it to stop being tracked properly.\n",
    "    + see test vid 1: 4:26 - 4:28, 6:04 - 6:06, 11:21 - 11:23, 12:58 - 13:00\n",
    "    + Increasing interval between frames seems to help deal with these gaps\n",
    "+ Produces about 680MB of intermediate data per 15 min video processed, mostly in background images.\n",
    "    + These are not used after object detection, so the anomaly detection part can be re-ran with different hyperparameters without them.\n",
    "+ Currently the detector was trained on the COCO dataset. The detector in the paper was trained on UA-DETRAC and VisDrone, with a gaussian blur applied. It should be fine tuned on these datasets.\n",
    "+ Much of the code on the paper's github just does not work. Most of it is full of errors, and does not reflect the algorithm in the paper. \n",
    "+ test vid 11: doesnt pick up on stopped car, but does when the repair van comes. Seems to work even with large camera movements. Seems to detect anomaly when brightness is increased. see 7:22\n",
    "+ test vid 6: Seems to be detecting the car fine, but there are periods of large drops in detection scores (see frames 10600-11000)\n",
    "+ Most of the time, the anomalies happen in the ignored area, so they are not picked up.\n",
    "    + Reducing the ignore_area_thresh and ignore_score_thresh parameters should help this.\n",
    "    + There is also the issue of moving anomalies. eg cars swerving off the road/out of camera view.\n",
    "+ Increasing the interval between detecting frames does not seem to impact performance significantly.\n",
    "    + Perhaps some sort of adaptive or 2 step detection would work. Run once with a large interval to produce candidate times, then go back with a finer interval to confirm.\n",
    "+ I want to write the code to run frame by frame, instead of one processing step at a time. This is needed if I want to run the program in a live setting.\n",
    "+ Background creation is significantly slow. \n",
    "    + Using SSD detecting every 30 frames: 25 fps, every 4 frames: 19 fps, every 600 frames: 27 fps.\n",
    "    + Background takes 37ms per frame, detection ~67ms per frame.\n",
    "    + Potential solution: change bg modelling so it only calculates every x frames, instead of calulating every frame and yielding every x frames.\n",
    "    + Problem was actually a bottleneck in reading images\n",
    "        + Changed VideoReader to work on a separate thread, and only decode images that it actually needs.\n",
    "        + Sped up process by ~4x\n",
    "    + Moving calulations to GPU was actually slower, running on CPU was significantly faster\n",
    "+ Using HTC model is ~450ms per frame. A 15 min video takes ~55mins to process at bg_interval=4, ~9mins at bg_interval=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 - asgard",
   "language": "python",
   "name": "py3-fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
